<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-06-30T23:13:45-05:00</updated><id>http://localhost:4000//</id><title type="html">The Metal Framework</title><subtitle>Resources and tutorials for Metal, MetalKit and Metal Performance Shaders.
</subtitle><entry><title type="html">Introducing Metal 2</title><link href="http://localhost:4000/2017/06/30/introducing-metal-2.html" rel="alternate" type="text/html" title="Introducing Metal 2" /><published>2017-06-30T00:00:00-05:00</published><updated>2017-06-30T00:00:00-05:00</updated><id>http://localhost:4000/2017/06/30/introducing-metal-2</id><content type="html" xml:base="http://localhost:4000/2017/06/30/introducing-metal-2.html">&lt;p&gt;This year’s &lt;code class=&quot;highlighter-rouge&quot;&gt;WWDC&lt;/code&gt; was probably the most important one ever, at least as far as we - the &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; developers - are concerned. I can wholeheartedly say it was the &lt;a href=&quot;https://twitter.com/gpu3d/status/873049387269738497&quot;&gt;best week of my life&lt;/a&gt;, for sure!&lt;/p&gt;

&lt;p&gt;Let’s get to the &lt;em&gt;Games and Graphics&lt;/em&gt; news. The &lt;code class=&quot;highlighter-rouge&quot;&gt;most unexpected&lt;/code&gt; trophy goes to the renaming of &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; to &lt;strong&gt;Metal 2&lt;/strong&gt;. It has the most significant additions and enhancements since it was first announced in &lt;code class=&quot;highlighter-rouge&quot;&gt;2014&lt;/code&gt;, true, but let’s admit it: no one saw this one coming. The &lt;code class=&quot;highlighter-rouge&quot;&gt;most anticipated&lt;/code&gt; trophy goes to the new &lt;strong&gt;ARKit&lt;/strong&gt; framework. We are only a few weeks after the keynote and there are already numerous bold and funny &lt;em&gt;Augmented Reality&lt;/em&gt; projects out there. &lt;a href=&quot;https://developer.apple.com/arkit/&quot;&gt;ARKit&lt;/a&gt; integrates with &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; easily. Finally, the &lt;code class=&quot;highlighter-rouge&quot;&gt;most influencing&lt;/code&gt; trophy goes to &lt;strong&gt;VR&lt;/strong&gt;. It is because of &lt;em&gt;Virtual Reality&lt;/em&gt; that we are now able to achieve lower latency, enhanced framerates, as well as more powerful internal and now also &lt;a href=&quot;https://developer.apple.com/development-kit/external-graphics/&quot;&gt;external GPUs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/vr.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;VR&quot; /&gt;&lt;/p&gt;

&lt;p&gt;New features were also added to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Model I/O&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SpriteKit&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SceneKit&lt;/code&gt; frameworks. Other interesting additions are the &lt;code class=&quot;highlighter-rouge&quot;&gt;CoreML&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Vision&lt;/code&gt; frameworks used for &lt;a href=&quot;https://developer.apple.com/machine-learning/&quot;&gt;machine learning&lt;/a&gt;. This article is only focusing on what’s new in &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;1). &lt;strong&gt;MPS&lt;/strong&gt; - the &lt;em&gt;Metal Performance Shaders&lt;/em&gt; are now also available on &lt;code class=&quot;highlighter-rouge&quot;&gt;macOS&lt;/code&gt; and the new additions to &lt;code class=&quot;highlighter-rouge&quot;&gt;MPS&lt;/code&gt; include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;four new image processing primitives (&lt;code class=&quot;highlighter-rouge&quot;&gt;Image Keypoints&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Bilinear Rescale&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Image Statistics&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Element-wise Arithmetic Operations&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;new linear algebra objects such as &lt;code class=&quot;highlighter-rouge&quot;&gt;MPSVector&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;MPSMatrix&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;MPSTemporaryMatrix&lt;/code&gt;, as well as &lt;em&gt;BLAS-style matrix-matrix and matrix-vector multiplication&lt;/em&gt; and &lt;em&gt;LAPACK-style triangular matrix factorization and linear solvers&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;a dozen new &lt;code class=&quot;highlighter-rouge&quot;&gt;CNN&lt;/code&gt; primitives.&lt;/li&gt;
  &lt;li&gt;the &lt;code class=&quot;highlighter-rouge&quot;&gt;Binary&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;XNOR&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Dilated&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Sub-pixel&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Transpose&lt;/code&gt; convolutions were added to the already existing &lt;code class=&quot;highlighter-rouge&quot;&gt;Standard&lt;/code&gt; convolution primitive.&lt;/li&gt;
  &lt;li&gt;a new &lt;code class=&quot;highlighter-rouge&quot;&gt;Neural Network Graph&lt;/code&gt; API was added which is useful for describing neural networks using filter and image nodes.&lt;/li&gt;
  &lt;li&gt;the &lt;code class=&quot;highlighter-rouge&quot;&gt;Recurrent Neural Networks&lt;/code&gt; are now coming to help the &lt;code class=&quot;highlighter-rouge&quot;&gt;CNNs&lt;/code&gt; one-to-one limitation and implement one-to-many and many-to-many relationships.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2). &lt;strong&gt;Argument Buffers&lt;/strong&gt; - likely the most important addition to the framework this year. In the traditional argument model, for each object we would call the various functions to set buffers, textures, samplers linearly and then at the end we would have our draw call for that object.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/ArgumentBuffers1.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Argument Buffers 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can imagine, the number of calls will increase drastically when multiplying the number of calls with the total number of objects and with the number of frames where all these objects need to be drawn. As a consequence this will limit the number of objects that will appear on the screen eventually.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/ArgumentBuffers2.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Argument Buffers 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Argument Buffers&lt;/code&gt; introduce an efficient new way of configuring how to use resources by adopting the &lt;em&gt;indirect&lt;/em&gt; behavior that the constants have, and applying it to textures, samplers, states, pointers to other buffers, and so on. The argument buffer will now only have &lt;code class=&quot;highlighter-rouge&quot;&gt;2 API calls per object&lt;/code&gt;: set the argument buffer and then draw. With this approach many more objects can be drawn.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/ArgumentBuffers3.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Argument Buffers 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using argument buffers is as easy as matching the shader data with the host data:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Material&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intensity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;texture2d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sampler&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aSampler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Material&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;material&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;On the &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt;, the argument buffers are created and used by an &lt;strong&gt;MTLArgumentEncoder&lt;/strong&gt; object and they can be blit between &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; easily:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;compute&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeIndirectArgumentEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;bufferIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;constantData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;storeBytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myPosition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;But it can get even better using the &lt;code class=&quot;highlighter-rouge&quot;&gt;dynamic indexing&lt;/code&gt; feature. A great use case is when rendering crowds. An array of argument buffers can pack the data together for all instances (characters). Then, instead of having two calls per object, now we can have only &lt;code class=&quot;highlighter-rouge&quot;&gt;2 API calls per frame&lt;/code&gt;: one to set the buffer and one to draw indexed primitives for a large instance count!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/ArgumentBuffers4.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Argument Buffers 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; will process per-instance geometry and color. The shader will now take an array of argument buffers as input, dynamically pick the character for any instance index, and return the geometry for that object:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Vertex&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;instanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Character&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crowd&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;uint&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Character&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crowd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Another use case for argument buffers is when running particle simulations. For this we have the &lt;code class=&quot;highlighter-rouge&quot;&gt;resource setting on the GPU&lt;/code&gt; feature which refers to having an array of argument buffers, one buffer for each particle (thread). All the particle properties (position, material, and so on) are created and stored in argument buffers on the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; so when a particle needs a specific property, such as a material, it will copy it from the argument buffers instead of getting it from the &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt; thus avoiding expensive copies between them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/ArgumentBuffers5.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Argument Buffers 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A copying kernel is straightforward and lets you assign constant values, do partial or complete copies between a source and a destination object:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reuse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Material&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Material&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;destination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intensity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;destination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aTexture&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;destination&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Finally, we also have the use case of referencing other argument buffers. Imagine a structure to represent an instance (character) that will have a pointer to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Material&lt;/code&gt; structure such that many instances can point to the same material. Likewise, imagine another structure to represent a tree of nodes where each &lt;code class=&quot;highlighter-rouge&quot;&gt;Node&lt;/code&gt; would have a pointer to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Instance&lt;/code&gt; structure which will act as an array of instances in the node:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Instance&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Material&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;material&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: for now, only &lt;code class=&quot;highlighter-rouge&quot;&gt;Tier 2&lt;/code&gt; devices support all these argument buffer features. Starting with &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal 2&lt;/code&gt; the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; devices are now classified as either &lt;code class=&quot;highlighter-rouge&quot;&gt;Tier 1&lt;/code&gt; (integrated) or &lt;code class=&quot;highlighter-rouge&quot;&gt;Tier 2&lt;/code&gt; (discrete).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;3). &lt;strong&gt;Raster Order Groups&lt;/strong&gt; - a new fragment shader synchronization primitive that allows more granular control of the order in which fragment shaders access memory. As an example, when working with custom blending, most graphics &lt;code class=&quot;highlighter-rouge&quot;&gt;APIs&lt;/code&gt; guarantee that blending happens in draw call order. However, the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; thread parallelism needs a way to prevent race conditions. &lt;code class=&quot;highlighter-rouge&quot;&gt;Raster Order Groups&lt;/code&gt; do that by providing us with an implicit &lt;code class=&quot;highlighter-rouge&quot;&gt;Wait&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/RasterOrderGroups.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Raster Order Groups&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In traditional blending mode race conditions are created:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;blend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texture2d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;access&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;texture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// non-atomic memory access without any synchronization&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oldColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someCustomBlendingFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oldColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;All that is needed is adding the &lt;code class=&quot;highlighter-rouge&quot;&gt;Raster Order Groups&lt;/code&gt; attribute to the texture (or resource) with conflicting accesses:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;fragment&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;blend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texture2d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;access&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 
				&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;texture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;raster_order_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// the GPU now waits on first access to raster ordered memory&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oldColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someCustomBlendingFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oldColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;4). &lt;strong&gt;ProMotion&lt;/strong&gt; - only for iPad Pro displays currently. Without &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; the typical framerate is &lt;code class=&quot;highlighter-rouge&quot;&gt;60&lt;/code&gt; FPS (&lt;code class=&quot;highlighter-rouge&quot;&gt;16.6&lt;/code&gt; ms/frame):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion1.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; the framerate goes up to &lt;code class=&quot;highlighter-rouge&quot;&gt;120&lt;/code&gt; FPS (&lt;code class=&quot;highlighter-rouge&quot;&gt;8.3&lt;/code&gt; ms/frame) which is really useful for user input such as touch gestures or pencil using:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion2.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; also gives us flexibility in when to refresh the display image so we do not need to have a fixed framerate. Without &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; there is inconsistency in image refreshing which does not cope well with the user experience. Developers usually trade away their peak framerate to constrain all of them to &lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt; FPS rather than the targeted &lt;code class=&quot;highlighter-rouge&quot;&gt;48&lt;/code&gt; FPS (&lt;code class=&quot;highlighter-rouge&quot;&gt;20.83&lt;/code&gt; ms/frame), to achieve consistency:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion3.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; we now have a refresh point every &lt;code class=&quot;highlighter-rouge&quot;&gt;4&lt;/code&gt; ms rather than every &lt;code class=&quot;highlighter-rouge&quot;&gt;16&lt;/code&gt; ms (the vertical white lines):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion4.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; is also helping in cases of dropped frames. Without &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; we could have a frame that missed the deadline by taking too long to display:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion5.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; fixes this too by only extending the frame with only &lt;code class=&quot;highlighter-rouge&quot;&gt;4&lt;/code&gt; more ms instead of a whole frame (&lt;code class=&quot;highlighter-rouge&quot;&gt;16.6&lt;/code&gt; ms):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/promotion6.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;ProMotion 6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UIKit&lt;/code&gt; animations use &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; automatically but to use &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; views you need to opt in by disabling the minimum frame duration in the project’s &lt;code class=&quot;highlighter-rouge&quot;&gt;Info.plist&lt;/code&gt; file. Then you can use one of the &lt;strong&gt;3&lt;/strong&gt; presentation &lt;code class=&quot;highlighter-rouge&quot;&gt;APIs&lt;/code&gt;. The traditional &lt;strong&gt;present(drawable:)&lt;/strong&gt; will present the image immediately after the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; has finished rendering the frame (&lt;code class=&quot;highlighter-rouge&quot;&gt;16.6&lt;/code&gt; ms on fixed framerate displays and &lt;code class=&quot;highlighter-rouge&quot;&gt;4&lt;/code&gt; ms on &lt;code class=&quot;highlighter-rouge&quot;&gt;ProMotion&lt;/code&gt; displays). The second &lt;code class=&quot;highlighter-rouge&quot;&gt;API&lt;/code&gt; is &lt;strong&gt;present(drawable, afterMinimumDuration:)&lt;/strong&gt; and provides maximum consistency from frame to frame on fixed framerate displays. The third &lt;code class=&quot;highlighter-rouge&quot;&gt;API&lt;/code&gt; is &lt;strong&gt;present(drawable, atTime:)&lt;/strong&gt; and is useful when building custom animation loops or when trying to sync the display image with other outputs such as audio. Here is an example of how to implement it:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;targetTime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;drawable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metalLayer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;nextDrawable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;commandBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;present&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drawable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;atTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// after 1-2 frames&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;presentationDelay&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drawable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;presentedTime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetTime&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;First, set a time when you want to display the drawable, then render the scene into a command buffer, then wait for the next frame(s) and finally examine the delay so you can adjust the next frame time.&lt;/p&gt;

&lt;p&gt;5). &lt;strong&gt;Direct to Display&lt;/strong&gt; - is the new way to send content from the renderer directly to external displays (eg. head mounted devices used in &lt;code class=&quot;highlighter-rouge&quot;&gt;VR&lt;/code&gt;) with the least amount of latency. There are two paths an image takes after the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; finished rendering it and before it ends on the display. The first one is the typical &lt;code class=&quot;highlighter-rouge&quot;&gt;UI&lt;/code&gt; scenario when the system is compositing it with other views and layers for a final image:&lt;/p&gt;

&lt;p&gt;￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/DirectToDisplay1.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Direct To Display 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When building a full screen application that does not require blending, scaling or other views/layers, the second path is allowing the display direct access to the memory where we rendered to, thus saving a lot of system resources and avoiding a lot of overhead:&lt;/p&gt;

&lt;p&gt;￼￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/DirectToDisplay2.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Direct To Display 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, this only happens when certain conditions are met:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the layer is opaque&lt;/li&gt;
  &lt;li&gt;there is no masking or rounded corners&lt;/li&gt;
  &lt;li&gt;full screen, or with opaque black bars and background&lt;/li&gt;
  &lt;li&gt;the rendered size is at most as large as the display size&lt;/li&gt;
  &lt;li&gt;color space and pixel format is compatible with display&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The colorspace requirements makes it easier to know when &lt;code class=&quot;highlighter-rouge&quot;&gt;Direct to Display&lt;/code&gt; mode will work. For example, it is easy to detect if you are using a &lt;code class=&quot;highlighter-rouge&quot;&gt;P3&lt;/code&gt; display and disable the &lt;code class=&quot;highlighter-rouge&quot;&gt;P3&lt;/code&gt; mode when trying to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Direct to Display&lt;/code&gt; mode.&lt;/p&gt;

&lt;p&gt;6). &lt;strong&gt;Other Features&lt;/strong&gt; - include but are not limited to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;memory usage queries&lt;/strong&gt; - there are now new &lt;code class=&quot;highlighter-rouge&quot;&gt;APIs&lt;/code&gt; to query memory use per allocation, as well as total &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; memory allocated by the device:&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;kt&quot;&gt;MTLResource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allocatedSize&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;MTLHeap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentAllocatedSize&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;MTLDevice&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentAllocatedSize&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SIMDGroup scoped functions&lt;/strong&gt; - allow data sharing between &lt;code class=&quot;highlighter-rouge&quot;&gt;SIMD&lt;/code&gt; groups directly in the registers by avoiding load/store operations:
￼&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/SIMDGroup.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;SIMD Group&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;non-uniform threadgroup sizes&lt;/strong&gt; - help us not waste &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; cycles and avoid working on edge/bound cases:
￼&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/nonuniform.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Non-uniform Threadgroup Sizes&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Viewport Arrays&lt;/strong&gt; on &lt;code class=&quot;highlighter-rouge&quot;&gt;macOS&lt;/code&gt; now support up to &lt;code class=&quot;highlighter-rouge&quot;&gt;16&lt;/code&gt; viewports for the vertex function to choose from when rendering, and is useful for &lt;code class=&quot;highlighter-rouge&quot;&gt;VR&lt;/code&gt; when combined with instancing.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multisample Pattern Control&lt;/strong&gt; - allows selecting where within a pixel the &lt;code class=&quot;highlighter-rouge&quot;&gt;MSAA&lt;/code&gt; sample patters are located and it’s useful for custom anti-aliasing.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Resource Heaps&lt;/strong&gt; are now also available on &lt;code class=&quot;highlighter-rouge&quot;&gt;macOS&lt;/code&gt;. It allows controlling the time of memory allocation, fast reallocation, aliasing of resources and group related resources for faster binding.&lt;/li&gt;
  &lt;li&gt;other features include:&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Feature&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Linear Textures&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Create textures from a &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLBuffer&lt;/code&gt; without copying.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Function Constant for Argument Indexes&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Specialize bytecodes to change the binding index for shader arguments.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Additional Vertex Array Formats&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Add some 1-/2-component vertex formats and a &lt;code class=&quot;highlighter-rouge&quot;&gt;BGRA8&lt;/code&gt; vertex format.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;IOSurface Textures&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Create &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLTextures&lt;/code&gt; from &lt;code class=&quot;highlighter-rouge&quot;&gt;IOSurfaces&lt;/code&gt; on &lt;code class=&quot;highlighter-rouge&quot;&gt;iOS&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Dual Source Blending&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Additional blending modes with two source parameters.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I made a table with the most important new features, which states whether the feature is new in the latest version of the operating system or not.
￼&lt;/p&gt;

&lt;p&gt;￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/features.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Feature Table&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, here are a few lines I wrote to test the differences between my integrated and discrete &lt;code class=&quot;highlighter-rouge&quot;&gt;GPUs&lt;/code&gt;:
￼&lt;/p&gt;

&lt;p&gt;￼&lt;img src=&quot;https://github.com/MetalKit/images/blob/master/gpuCompare.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;GPU comparison&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All images were taken from &lt;code class=&quot;highlighter-rouge&quot;&gt;WWDC&lt;/code&gt; presentations and the &lt;a href=&quot;https://github.com/MetalKit/metal&quot;&gt;source code&lt;/a&gt; is posted on &lt;code class=&quot;highlighter-rouge&quot;&gt;Github&lt;/code&gt; as usual.&lt;/p&gt;

&lt;p&gt;Until next time!&lt;/p&gt;</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">This year’s WWDC was probably the most important one ever, at least as far as we - the Metal developers - are concerned. I can wholeheartedly say it was the best week of my life, for sure!</summary></entry><entry><title type="html">Working with memory in Metal part 2</title><link href="http://localhost:4000/2017/05/26/working-with-memory-in-metal-part-2.html" rel="alternate" type="text/html" title="Working with memory in Metal part 2" /><published>2017-05-26T00:00:00-05:00</published><updated>2017-05-26T00:00:00-05:00</updated><id>http://localhost:4000/2017/05/26/working-with-memory-in-metal-part-2</id><content type="html" xml:base="http://localhost:4000/2017/05/26/working-with-memory-in-metal-part-2.html">There are a couple of topics we need to discuss in more depth about working with memory. Last time we have seen that to create `MTLBuffer` objects we have 3 options: by creating a new memory allocation with new data, by copying data from an existing allocation into a new allocation and by reusing an existing storage allocation which does not copy data. Since we haven't looked at the memory before, let's check that is actually true. First we copy data into another allocation:
 
{% highlight swift %}let count = 2000
let length = count * MemoryLayout&lt; Float &gt;.stride
var myVector = [Float](repeating: 0, count: count)
let myBuffer = device.makeBuffer(bytes: myVector, length: length, options: [])
withUnsafePointer(to: &amp;myVector) { print($0) }
print(myBuffer.contents())
{% endhighlight %}
 
&gt; Note: the __withUnsafePointer()__ function gives us the memory address of the actual data on the heap instead of the address of the pointer (from the stack) that wraps that data.
 
Your output should look similar to this:
 
{% highlight swift %}0x000000010043e0e0
0x0000000102afd000
{% endhighlight %}

The two data buffers are definitely stored at different memory locations. Now let's use the `no-copy` option:
 
{% highlight swift %}var memory: UnsafeMutableRawPointer? = nil
let alignment = 0x1000
let allocationSize = (length + alignment - 1) &amp; (~(alignment - 1))
posix_memalign(&amp;memory, alignment, allocationSize)
let myBuffer = device.makeBuffer(bytesNoCopy: memory!, 
				 length: allocationSize, 
				 options: [], 
				 deallocator: { (pointer: UnsafeMutableRawPointer, _: Int) in 
					free(pointer) 
				 })
print(memory!)
print(myBuffer.contents())
{% endhighlight %}
 
First, we create a pointer to our data which (data) we'll store on the heap. For this we need to page-align it. We set the page size to be `4K` (`1000` in hexadecimal). We need to also round the buffer size to match the alignment. We used a bitwise `AND` to avoid division which is a very expensive operation. Otherwise we would just round like this: 
 
{% highlight swift %}let allocationSize = ((length + alignment - 1) / alignment) * alignment
{% endhighlight %}
 
Your output should look similar to this:
 
{% highlight swift %}0x000000010300c000
0x000000010300c000
{% endhighlight %}
 
Notice the last three digits in the addresses above? Those come from page-alinging the data because an address is determined by `0 mod pageSize`, hence the last three `0`'s, which makes sense since our page size is `0x1000`.
 
Let's now move to `Storage Modes` which we briefly mentioned last time. There are basically only four main rules to keep in mind, one for each of the storage modes:
 
|Mode|Description|
|:--|:--|
|`Shared`|_default_ on `macOS` buffers, `iOS/tvOS` resources; not available on `macOS` textures.|
|`Private`|mostly use when data is only accessed by `GPU`.|
|`Memoryless`|only for `iOS/tvOS` on-chip temporary render targets (textures).|
|`Managed`|_default_ mode for `macOS` textures; not available on `iOS/tvOS` resources.|
||
 
For a better big picture, here is the full cheat sheet in case you might find it easier to use than remembering the rules above:
 
![alt text](https://github.com/MetalKit/images/blob/master/storage-modes.png?raw=true &quot;Storage Modes&quot;)
 
The most complicated case is when working with `macOS` buffers and when the data needs to be accessed by both the `CPU` and the `GPU`. We choose the storage mode based on whether one or more of the following conditions are true:
 
* __Private__ - for large-sized data that changes at most once, so it is not &quot;dirty&quot; at all. create a source buffer with a `Shared` mode and then blit its data into a destination buffer with a `Private` mode. resource coherency is not necessary in this case as the data is only accessed by the `GPU`. this operation is the least expensive (a one-time cost).
* __Managed__ - for medium-sized data that changes infrequently (every few frames), so it is partially &quot;dirty&quot;. one copy of the data is stored in system memory for the `CPU` and another copy is stored in `GPU` memory. resource coherency is explicitly managed by synchronizing the two copies.
* __Shared__ - for small-sized data that is updated every frame, so it is fully dirty. data resides in the system memory and is visible and modifyable by both the `CPU` and the `GPU`. resource coherency is only guaranteed within command buffer boundaries.
 
How to make sure coherency is guaranteed? First, make sure that all the modifications done by the `CPU` finished before the command buffer was committed (check if the command buffer status property is __MTLCommandBufferStatusCommitted__). After the `GPU` finishes executing the command buffer, the `CPU` should only start making modifications again only after the `GPU` is signaling the `CPU` that the command buffer finished executing (check if the command buffer status property is __MTLCommandBufferStatusCompleted__).
 
Finally, let's see how synchronization is done for `macOS` resources. For buffers: after a `CPU` write use __didModifyRange()__ to inform the `GPU` of the changes so `Metal` can update that data region only; after a `GPU` write use __synchronize(resource:)__ within a blit operation, to refresh the caches so the `CPU` can access the updated data. For textures: after a `CPU` write use one of the two __replace()__ region functions to inform the `GPU` of the changes so `Metal` can update that data region only; after a `GPU` write use one of the two __synchronize()__ functions within a blit operation to allow `Metal` to update the system memory copy after the `GPU` finished modifying the data. 
 
The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.
 
Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">There are a couple of topics we need to discuss in more depth about working with memory. Last time we have seen that to create MTLBuffer objects we have 3 options: by creating a new memory allocation with new data, by copying data from an existing allocation into a new allocation and by reusing an existing storage allocation which does not copy data. Since we haven’t looked at the memory before, let’s check that is actually true. First we copy data into another allocation:

let count = 2000
let length = count * MemoryLayout&amp;lt; Float &amp;gt;.stride
var myVector = [Float](repeating: 0, count: count)
let myBuffer = device.makeBuffer(bytes: myVector, length: length, options: [])
withUnsafePointer(to: &amp;amp;myVector) { print($0) }
print(myBuffer.contents())


  Note: the withUnsafePointer() function gives us the memory address of the actual data on the heap instead of the address of the pointer (from the stack) that wraps that data.


Your output should look similar to this:

0x000000010043e0e0
0x0000000102afd000</summary></entry><entry><title type="html">Working with memory in Metal</title><link href="http://localhost:4000/2017/04/30/working-with-memory-in-metal.html" rel="alternate" type="text/html" title="Working with memory in Metal" /><published>2017-04-30T00:00:00-05:00</published><updated>2017-04-30T00:00:00-05:00</updated><id>http://localhost:4000/2017/04/30/working-with-memory-in-metal</id><content type="html" xml:base="http://localhost:4000/2017/04/30/working-with-memory-in-metal.html">Today we look at how memory is managed when working with the `GPU`. The `Metal` framework defines memory sources as `MTLBuffer` objects which are typeless and unformatted allocations of memory (any type of data), and `MTLTexture` objects which are formatted allocations of memory holding image data. We only look at buffers in this article.

To create `MTLBuffer` objects we have 3 options:

* __makeBuffer(length:options:)__ creates a `MTLBuffer` object with a new allocation.
* __makeBuffer(bytes:length:options:)__ copies data from an existing allocation into a new allocation.
* __makeBuffer(bytesNoCopy:length:options:deallocator:)__ reuses an existing storage allocation.

Let's create a couple of buffers and see how data is being sent to the `GPU` and then sent back to the `CPU`. We first create a buffer for both input and output data and initialize them to some values:

{% highlight swift %}let count = 1500
var myVector = [Float](repeating: 0, count: count)
var length = count * MemoryLayout&lt; Float &gt;.stride
var outBuffer = device.makeBuffer(bytes: myVector, length: length, options: [])
for (index, value) in myVector.enumerated() { myVector[index] = Float(index) }
var inBuffer = device.makeBuffer(bytes: myVector, length: length, options: [])
{% endhighlight %}

The new __MemoryLayout&lt; Type &gt;.stride__ syntax was introduced in `Swift 3` to replace the old `strideof(Type)` function. By the way, we use `.stride` instead of `.size` for memory alignment reasons. The __stride__ is the number of bytes moved when a pointer is incremented. The next step is to tell the command encoder about our buffers:

{% highlight swift %}encoder.setBuffer(inBuffer, offset: 0, at: 0)
encoder.setBuffer(outBuffer, offset: 0, at: 1)
{% endhighlight %}

&gt; Note: the Metal Best Practices Guide states that we should always avoid creating buffers when our data is less than __4 KB__ (up to a thousand `Floats`, for example). In this case we should simply use the __setBytes()__ function instead of creating a buffer. 

The final step is to read the data the `GPU` sent back by using the __contents()__ function to bind the memory data to our output buffer:

{% highlight swift %}let result = outBuffer.contents().bindMemory(to: Float.self, capacity: count)
var data = [Float](repeating:0, count: count)
for i in 0 ..&lt; count { data[i] = result[i] }
{% endhighlight %}

`Metal` resources must be configured for fast memory access and driver performance optimizations. Resource __storage modes__ let us define the storage location and access permissions for our buffers and textures. If you take a look above where we created our buffers, we used the default option (__[]__) as the storage mode. 

All `iOS` and `tvOS` devices support a _unified memory model_ where both the `CPU` and the `GPU` share the system memory, while `macOS` devices support a _discrete memory model_ where the `GPU` has its own memory. In `iOS` and `tvOS`, the __Shared__ mode (`MTLStorageModeShared`) defines system memory accessible to both `CPU` and `GPU`, while __Private__ mode (`MTLStorageModePrivate`) defines system memory accessible only to the GPU. The `Shared` mode is the default storage mode on all three operating systems.

![alt text](https://developer.apple.com/library/content/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/Art/ResourceManagement_iOStvOSMemory_2x.png &quot;iOS and tvOS&quot;)

Besides these two storage modes, `macOS` also has a __Managed__ mode (`MTLStorageModeManaged`) that defines a synchronized memory pair for a resource, with one copy in system memory and another in video memory for faster CPU and GPU local accesses.
 
![alt text](https://developer.apple.com/library/content/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/Art/ResourceManagement_OSXMemory_2x.png &quot;macOS&quot;)

Now let's look at what happens on the `GPU` when we send it data buffers. Here is a typical vertex shader example:

{% highlight swift %}vertex Vertices vertex_func(const device Vertices *vertices [[buffer(0)]], 
            		    constant Uniforms &amp;uniforms [[buffer(1)]], 
            		    uint vid [[vertex_id]]) 
{
	...
}
{% endhighlight %}

The `Metal Shading Language` implements address space qualifiers to specify the region of memory where a function variable or argument is allocated: 

* __device__ - refers to buffer memory objects allocated from the device memory pool that are both readable and writeable unless the keyword __const__ preceeds it in which case the objects are only readable.
* __constant__ - refers to buffer memory objects allocated from the device memory pool but that are `read-only`. Variables in program scope must be declared in the constant address space and initialized during the declaration statement. The constant address space is optimized for multiple instances executing a graphics or kernel function accessing the same location in the buffer.
* __threadgroup__ - is used to allocate variables used by a kernel functions only and they are allocated for each threadgroup executing the kernel, are shared by all threads in a threadgroup and exist only for the lifetime of the threadgroup that is executing the kernel. 
* __thread__ - refers to the per-thread memory address space. Variables allocated in this address space are not visible to other threads. Variables declared inside a graphics or kernel function are allocated in the thread address space.

As a bonus, let's also look at another way of accessing memory locations in `Swift 3`. This code snippet belongs to a previous article, [The Model I/O framework](http://metalkit.org/2016/08/30/the-model-i-o-framework.html), so we will not go again into details about voxels. Just think of an array that we need to iterate over to get values:

{% highlight swift %}let url = Bundle.main.url(forResource: &quot;teapot&quot;, withExtension: &quot;obj&quot;)
let asset = MDLAsset(url: url)
let voxelArray = MDLVoxelArray(asset: asset, divisions: 10, patchRadius: 0)
if let data = voxelArray.voxelIndices() {
    data.withUnsafeBytes { (voxels: UnsafePointer&lt;MDLVoxelIndex&gt;) -&gt; Void in
        let count = data.count / MemoryLayout&lt;MDLVoxelIndex&gt;.size
        let position = voxelArray.spatialLocation(ofIndex: voxels.pointee)
        print(position)
    }
}
{% endhighlight %} 

In this case, the `MDLVoxelArray` object has a function named `spatialLocation()` which lets us iterate through the array by using an `UnsafePointer` of the `MDLVoxelIndex` type and accessing the data through the `pointee` at each location. In this example we are only printing out the first value found at that address but a simple loop will let us get all of them like this:

{% highlight swift %}var voxelIndex = voxels
for _ in 0..&lt;count {
    let position = voxelArray.spatialLocation(ofIndex: voxelIndex.pointee)
    print(position)
    voxelIndex = voxelIndex.successor()
}
{% endhighlight %}

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Today we look at how memory is managed when working with the GPU. The Metal framework defines memory sources as MTLBuffer objects which are typeless and unformatted allocations of memory (any type of data), and MTLTexture objects which are formatted allocations of memory holding image data. We only look at buffers in this article.</summary></entry><entry><title type="html">Ambient Occlusion in Metal</title><link href="http://localhost:4000/2017/03/22/ambient-occlusion-in-metal.html" rel="alternate" type="text/html" title="Ambient Occlusion in Metal" /><published>2017-03-22T00:00:00-05:00</published><updated>2017-03-22T00:00:00-05:00</updated><id>http://localhost:4000/2017/03/22/ambient-occlusion-in-metal</id><content type="html" xml:base="http://localhost:4000/2017/03/22/ambient-occlusion-in-metal.html">Today we will be looking into __ambient occlusion__. We are going to work on the playground we used in [Shadows in Metal part 2](http://metalkit.org/2017/02/28/shadows-in-metal-part-2.html) and build up on that. First, let’s add a new object type - a rectangular box:

{% highlight swift %}struct Box {
    float3 center;
    float size;
    Box(float3 c, float s) {
        center = c;
        size = s;
    }
};
{% endhighlight %}

Next, let’s also add a new distance function for our new struct:

{% highlight swift %}float distToBox(Ray r, Box b) {
    float3 d = abs(r.origin - b.center) - float3(b.size);
    return min(max(d.x, max(d.y, d.z)), 0.0) + length(max(d, 0.0));
}
{% endhighlight %}

Then, update our scene to something new: 

{% highlight swift %}float distToScene(Ray r) {
    Plane p = Plane(0.0);
    float d2p = distToPlane(r, p);
    Sphere s1 = Sphere(float3(0.0, 0.5, 0.0), 8.0);
    Sphere s2 = Sphere(float3(0.0, 0.5, 0.0), 6.0);
    Sphere s3 = Sphere(float3(10., -5., -10.), 15.0);
    Box b = Box(float3(1., 1., -4.), 1.);
    float dtb = distToBox(r, b);
    float d2s1 = distToSphere(r, s1);
    float d2s2 = distToSphere(r, s2);
    float d2s3 = distToSphere(r, s3);
    float dist = differenceOp(d2s1, d2s2);
    dist = differenceOp(dist, d2s3);
    dist = unionOp(dist, dtb);
    dist = unionOp(d2p, dist);
    return dist;
}
{% endhighlight %}

What we did here was to first draw a sphere with a radius of `8`, one with a radius of `6` and take the difference between them. Since they have the same center the smaller one would not be visible unless we made a cross sectioning somehow. That was exactly why we used a third sphere, much larger and with a different center. We took the difference again and we could now see the result of the first difference. Finally, we added a box in there for a nicer, more diverse view. If you run the playground now, you should see something similar: 

![alt text](https://github.com/MetalKit/images/raw/master/ao_1.png &quot;1&quot;)

Next, let’s delete the __lighting()__ and __shadow()__ functions as we don’t need them anymore. Also, delete the __Light__ struct and its two instances inside the kernel. Now let's create an `ambient occlusion` surrogate function:

{% highlight swift %}float ao(float3 pos, float3 n) {
    return n.y * 0.5 + 0.5;
}
{% endhighlight %}

We’re just using the normal’s `y` component for light, which is like having a light directly above. Inside the kernel, right after creating the normal (inside the `else` block), call the `ao()` function:

{% highlight swift %}float o = ao(ray.origin, n);
col = col * o;
{% endhighlight %}

There are no shadows anymore, only a basic (directly above) light. If you run the playground now, you should see something similar:

![alt text](https://github.com/MetalKit/images/raw/master/ao_2.png &quot;2&quot;)

Time to get some real `ambient occlusion` now. _Ambient_ means the light does not come from a well defined light source but rather means general background lighting. _Occlusion_ means how much ambient light is blocked. We take the point on the surface where our ray hits and look at what’s around it. If there’s an object anywhere around it, that will block most of the light in the scene, so this is a dark area. If there’s nothing around it, then the area is well lit. For in between situations though, we need to figure out more precisely how much light was occluded. Introducing the __cone tracing__ concept.

The idea of `cone tracing` is using a cone in the scene, instead of a ray. If the cone intersects an object, we don’t just have a simple `true/false` result. We can find out how much of the cone the object covers at that point. But how do we even trace a cone? We could make a cone using many spheres. Try to imagine several spheres along a line, very small at one end, big at the other end. This is as good a cone approximation we can get here. Here are the steps we want to take:

- Start at the point on the surface
- March out from the surface, along the normal
- For each iteration, determine how much of the sphere is filled by the scene using distance function
- For each iteration, double the distance from the surface, and also double the size of the sphere

Since we are doubling the sphere size at each step, that means we travel out from the surface very fast so we need fewer iterations. That also gives us a nice wide cone. Here is the complete `ao()` function:

{% highlight swift %}float ao(float3 pos, float3 n) {
    float eps = 0.01;
    pos += n * eps * 2.0;
    float occlusion = 0.0;
    for (float i=1.0; i&lt;10.0; i++) {
        float d = distToScene(Ray(pos, float3(0)));
        float coneWidth = 2.0 * eps;
        float occlusionAmount = max(coneWidth - d, 0.);
        float occlusionFactor = occlusionAmount / coneWidth;
        occlusionFactor *= 1.0 - (i / 10.0);
        occlusion = max(occlusion, occlusionFactor);
        eps *= 2.0;
        pos += n * eps;
    }
    return max(0.0, 1.0 - occlusion);
}
{% endhighlight %}

Let's go over the code, line by line. First we define the __eps__ variable which is both the cone radius and the distance from the surface. Then, we move away a bit to prevent hitting surface we're moving away from. Next, we define the __occlusion__ variable which is initially nil (scene is all lit). Then, we enter the loop and at each iteration we get the scene distance, double the radius so we know how much of the cone is occluded, make sure we eliminate negative values for the light, get the amount (ratio) of occlusion scaled by the cone width, set a lower impact for more distant occluders (the iteration count gives us this), preserve the highest occlusion value so far, double the __eps__ value and finally move along the normal by that distance. We then return a value that represents how much light reaches this point.  

Now lets have a __camera__ struct. It needs a position. Instead of camera direction we'll just store a __ray__. Finally the __rayDivergence__ gives us a factor of how much the ray spreads.

{% highlight swift %}struct Camera {
    float3 position;
    Ray ray = Ray(float3(0), float3(0));
    float rayDivergence;
    Camera(float3 pos, Ray r, float div) {
        position = pos;
        ray = r;
        rayDivergence = div;
    }
};
{% endhighlight %}

Next, we need to set up the camera. It needs the camera position, a look-at target, the field of view and the view coordinates:

{% highlight swift %}Camera setupCam(float3 pos, float3 target, float fov, float2 uv, int x) {
    uv *= fov;
    float3 cw = normalize(target - pos );
    float3 cp = float3(0.0, 1.0, 0.0);
    float3 cu = normalize(cross(cw, cp));
    float3 cv = normalize(cross(cu, cw));
    Ray ray = Ray(pos, normalize(uv.x * cu + uv.y * cv + 0.5 * cw));
    Camera cam = Camera(pos, ray, fov / float(x));
    return cam;
}
{% endhighlight %}

Now we just need to initialize the camera. We'll have it circling the scene, looking at the center __(0,0,0)__. Add this to the kernel, just after you set up the `uv` variable:
 
{% highlight swift %}float3 camPos = float3(sin(time) * 10., 3., cos(time) * 10.);
Camera cam = setupCam(camPos, float3(0), 1.25, uv, width);
{% endhighlight %}
 
Then delete the __ray__ variable, and replace everywhere it was used in the kernel with __cam.ray__ instead. If you run the playground now, you should see something similar:

![alt text](https://github.com/MetalKit/images/raw/master/ao_3.png &quot;3&quot;)

To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/4ltSWf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual. I want to thanks [Chris](https://twitter.com/_psonice) again for his assistance.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Today we will be looking into ambient occlusion. We are going to work on the playground we used in Shadows in Metal part 2 and build up on that. First, let’s add a new object type - a rectangular box:</summary></entry><entry><title type="html">Shadows in Metal part 2</title><link href="http://localhost:4000/2017/02/28/shadows-in-metal-part-2.html" rel="alternate" type="text/html" title="Shadows in Metal part 2" /><published>2017-02-28T00:00:00-06:00</published><updated>2017-02-28T00:00:00-06:00</updated><id>http://localhost:4000/2017/02/28/shadows-in-metal-part-2</id><content type="html" xml:base="http://localhost:4000/2017/02/28/shadows-in-metal-part-2.html">In this second part of the series, we will be looking into __soft shadows__. We are going to work on the playground we used in [Raymarching in Metal](http://metalkit.org/2016/12/30/raymarching-in-metal.html) and build up on that because it was already set up for `3D` objects. Let’s set up a basic scene that has a sphere, a plane, a light and a ray: 

{% highlight swift %}struct Ray {
    float3 origin;
    float3 direction;
    Ray(float3 o, float3 d) {
        origin = o;
        direction = d;
    }
};

struct Sphere {
    float3 center;
    float radius;
    Sphere(float3 c, float r) {
        center = c;
        radius = r;
    }
};

struct Plane {
    float yCoord;
    Plane(float y) {
        yCoord = y;
    }
};

struct Light {
    float3 position;
    Light(float3 pos) {
        position = pos;
    }
};
{% endhighlight %}

Next, we create a few `distance operation` functions that help us determine distances between elements of the scene: 

{% highlight swift %}float unionOp(float d0, float d1) {
    return min(d0, d1);
}

float differenceOp(float d0, float d1) {
    return max(d0, -d1);
}

float distToSphere(Ray ray, Sphere s) {
    return length(ray.origin - s.center) - s.radius;
}

float distToPlane(Ray ray, Plane plane) {
    return ray.origin.y - plane.yCoord;
}
{% endhighlight %}

Next, we create a __distanceToScene()__ function which gives us the closest distance to any object in the scene. We use these functions to generate a shape that looks like a hollow sphere with holes:

{% highlight swift %}float distToScene(Ray r) {
    Plane p = Plane(0.0);
    float d2p = distToPlane(r, p);
    Sphere s1 = Sphere(float3(2.0), 1.9);
    Sphere s2 = Sphere(float3(0.0, 4.0, 0.0), 4.0);
    Sphere s3 = Sphere(float3(0.0, 4.0, 0.0), 3.9);
    Ray repeatRay = r;
    repeatRay.origin = fract(r.origin / 4.0) * 4.0;
    float d2s1 = distToSphere(repeatRay, s1);
    float d2s2 = distToSphere(r, s2);
    float d2s3 = distToSphere(r, s3);
    float dist = differenceOp(d2s2, d2s3);
    dist = differenceOp(dist, d2s1);
    dist = unionOp(d2p, dist);
    return dist;
}
{% endhighlight %}

Everything we wrote so far is old code, just refactored from the _Raymarching_ article. Let's talk about __normals__ and why they are needed. If we have a flat floor - like our plane - the normal is always `(0, 1, 0)`, that is, pointing up. This case is trivial though. The normal in `3D` space is a `float3` and we need to know its position on the ray. Assume the ray just touches the left side of the sphere. The normal should be `(-1, 0, 0)`, that is, pointing to the left and away from the sphere. If the ray moves slightly to the right of that point, it’s inside the sphere `(eg. -0.001)`. If the ray moves slightly to the left, it’s outside the sphere `(eg. 0.001)`. If we subtract left from right we get `-0.001 - 0.001 = -0.002` which points to the left, so this is our `x` coordinate of the normal. We then repeat this for `y` and `z`. We use a `2D` vector named __eps__ so we can easily do [vector swizzling](https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)) using the chosen value `0.001` for various coordinates as needed in each case: 

{% highlight swift %}float3 getNormal(Ray ray) {
    float2 eps = float2(0.001, 0.0);
    float3 n = float3(distToScene(Ray(ray.origin + eps.xyy, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.xyy, ray.direction)),
                      distToScene(Ray(ray.origin + eps.yxy, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.yxy, ray.direction)),
                      distToScene(Ray(ray.origin + eps.yyx, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.yyx, ray.direction)));
    return normalize(n);
}
{% endhighlight %}

Finally, we are ready to see some visuals. We again use the old `Raymarching` code and at the end of the kernel function we just add the normal so we can interpolate it with the color for every pixel:

{% highlight swift %}kernel void compute(texture2d&lt;float, access::write&gt; output [[texture(0)]],
                    constant float &amp;time [[buffer(0)]],
                    uint2 gid [[thread_position_in_grid]]) {
    int width = output.get_width();
    int height = output.get_height();
    float2 uv = float2(gid) / float2(width, height);
    uv = uv * 2.0 - 1.0;
    uv.y = -uv.y;
    Ray ray = Ray(float3(0., 4., -12), normalize(float3(uv, 1.)));
    float3 col = float3(0.0);
    for (int i=0; i&lt;100; i++) {
        float dist = distToScene(ray);
        if (dist &lt; 0.001) {
            col = float3(1.0);
            break;
        }
        ray.origin += ray.direction * dist;
    }
    float3 n = getNormal(ray);
    output.write(float4(col * n, 1.0), gid);
}
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_4.png &quot;4&quot;)

Now that we have normals, we can calculate lighting for each pixel in the scene, using the __lighting()__ function. First we need to know the direction to the light (`lightRay`) which we get by normalizing the light position and the current ray. For __diffuse__ lighting we need the angle between the normal and the `lightRay`, that is, the dot product of the two. For __specular__ lighting we need reflections on surfaces, and they depend on the angle we’re looking at. The difference is in this case we first cast a ray into the scene, reflect it from the surface and then we measure the angle between the reflected ray and the `lightRay`. We then take a high power of that value to make it much sharper. Finally we return the combined light:

{% highlight swift %}float lighting(Ray ray, float3 normal, Light light) {
    float3 lightRay = normalize(light.position - ray.origin);
    float diffuse = max(0.0, dot(normal, lightRay));
    float3 reflectedRay = reflect(ray.direction, normal);
    float specular = max(0.0, dot(reflectedRay, lightRay));
    specular = pow(specular, 200.0);
    return diffuse + specular;
}
{% endhighlight %}

Replace the last line in the kernel function with these lines:

{% highlight swift %}Light light = Light(float3(sin(time) * 10.0, 5.0, cos(time) * 10.0));
float l = lighting(ray, n, light);
output.write(float4(col * l, 1.0), gid);
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_5.png &quot;5&quot;)

Next, shadows! We pretty much use the __shadow()__ function from the first part of this series, with few modifications. We normalize the direction of the light (`lightDir`) and then we just keep updating `distAlongRay` as we march along the ray:

{% highlight swift %}float shadow(Ray ray, Light light) {
    float3 lightDir = light.position - ray.origin;
    float lightDist = length(lightDir);
    lightDir = normalize(lightDir);
    float distAlongRay = 0.01;
    for (int i=0; i&lt;100; i++) {
        Ray lightRay = Ray(ray.origin + lightDir * distAlongRay, lightDir);
        float dist = distToScene(lightRay);
        if (dist &lt; 0.001) {
            return 0.0;
            break;
        }
        distAlongRay += dist;
        if (distAlongRay &gt; lightDist) { break; }
    }
    return 1.0;
}
{% endhighlight %}

Replace the last line in the kernel function with these lines:

{% highlight swift %}float s = shadow(ray, light);
output.write(float4(col * l * s, 1.0), gid);
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_6.png &quot;6&quot;)

Let's get some `soft shadows` in the scene. In real life, a shadow spreads out the farther it gets from an object. For example, if there is a cube on the floor, at a cube's vertex we get a sharp shadow but farther away from the cube it looks more like a blurred shadow. In other words, we start at some point on the floor, we march towards the light and either hit or miss. Hard shadows are straightforward: we hit something, it's in the shadow. Soft shadows have in-between stages. Update the __shadow()__ function with these lines:

{% highlight swift %}float shadow(Ray ray, float k, Light l) {
    float3 lightDir = l.position - ray.origin;
    float lightDist = length(lightDir);
    lightDir = normalize(lightDir);
    float eps = 0.1;
    float distAlongRay = eps * 2.0;
    float light = 1.0;
    for (int i=0; i&lt;100; i++) {
        Ray lightRay = Ray(ray.origin + lightDir * distAlongRay, lightDir);
        float dist = distToScene(lightRay);
        light = min(light, 1.0 - (eps - dist) / eps);
        distAlongRay += dist * 0.5;
        eps += dist * k;
        if (distAlongRay &gt; lightDist) { break; }
    }
    return max(light, 0.0);
}
{% endhighlight %}

You will notice that we are starting with a white (`1.0`) light this time and we use an attenuator (__k__) to get various (intermediate) values of light. The __eps__ variable tells us how much wider the beam is as we go out into the scene. A thin beam means sharp shadow while a wide beam means soft shadow. We start with a small `distAlongRay` because otherwise the surface at this point would shadow itself. We then travel along the ray as we did for the hard shadows, then we get the distance to the scene, after that we subtract `dist` from `eps` (the beam width) and divide it by `eps`. This gives us the percentage of beam covered. If we invert it (`1 - beam width`) we get the percentage of beam that is in the light. We take the minimum of this new value and `light` to preserve the darkest shadow as we march along the ray. We then again move along the ray and increase the beam width in proportion to the distance traveled and scaled by `k`. If we're past the light, we break out of the loop. Finally, we want to avoid negative values for the light so we return the maximum between __0.0__ and the value of light. Now let's adapt the kernel code to work with the new `shadow()` function:

{% highlight swift %}float3 col = float3(1.0);
bool hit = false;
for (int i=0; i&lt;200; i++) {
    float dist = distToScene(ray);
    if (dist &lt; 0.001) {
        hit = true;
        break;
    }
    ray.origin += ray.direction * dist;
}
if (!hit) {
    col = float3(0.5);
} else {
    float3 n = getNormal(ray);
    Light light = Light(float3(sin(time) * 10.0, 5.0, cos(time) * 10.0));
    float l = lighting(ray, n, light);
    float s = shadow(ray, 0.3, light);
    col = col * l * s;
}
Light light2 = Light(float3(0.0, 5.0, -15.0));
float3 lightRay = normalize(light2.position - ray.origin);
float fl = max(0.0, dot(getNormal(ray), lightRay) / 2.0);
col = col + fl;
output.write(float4(col, 1.0), gid);
{% endhighlight %}

Notice we switched to having a rather white color by default. Then we added a boolean named __hit__ that tells us if we hit the object or not. We determine we have a hit if the distance to scene is within __0.001__. If we didn't hit anything, just color everything in grey, otherwise determine the shadow value. At the end we just add another (fixed) light source in front of the scene so see the shadows in greater detail. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_7.png &quot;7&quot;)

To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/XltSWf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">In this second part of the series, we will be looking into soft shadows. We are going to work on the playground we used in Raymarching in Metal and build up on that because it was already set up for 3D objects. Let’s set up a basic scene that has a sphere, a plane, a light and a ray:</summary></entry><entry><title type="html">Shadows in Metal part 1</title><link href="http://localhost:4000/2017/01/31/shadows-in-metal-part-1.html" rel="alternate" type="text/html" title="Shadows in Metal part 1" /><published>2017-01-31T00:00:00-06:00</published><updated>2017-01-31T00:00:00-06:00</updated><id>http://localhost:4000/2017/01/31/shadows-in-metal-part-1</id><content type="html" xml:base="http://localhost:4000/2017/01/31/shadows-in-metal-part-1.html">A quite important topic in `Computer Graphics` is _lighting and shadows_. This will be a first episode from a multi-part series about __Shadows__ in `Metal`. We are going to work on the playground we used in [Using metal part 15](http://metalkit.org/2016/06/23/using-metalkit-part-15.html) and build up on that. Let’s set up a basic scene: 

{% highlight swift %}float differenceOp(float d0, float d1) {
    return max(d0, -d1);
}

float distanceToRect( float2 point, float2 center, float2 size ) {
    point -= center;
    point = abs(point);
    point -= size / 2.;
    return max(point.x, point.y);
}

float distanceToScene( float2 point ) {
    float d2r1 = distanceToRect( point, float2(0.), float2(0.45, 0.85) );
    float2 mod = point - 0.1 * floor(point / 0.1);
    float d2r2 = distanceToRect( mod, float2( 0.05 ), float2(0.02, 0.04) );
    float diff = differenceOp(d2r1, d2r2);
    return diff;
}
{% endhighlight %}

We first created the __differenceOp()__ function which returns the difference between two signed distances. This comes in handy when we want to _carve_ shapes out of other shapes. Next, we created the __distanceToRect()__ function which determines if a given point is either inside or outside a rectangle. On the `1st` line we offset the current coordinates by the given center. On the `2nd` line we get the symmetrical coordinates of the given point. On the `3rd` line we get the distance to any edge. Then, we created the __distanceToScene()__ function which gives us the closest distance to any object in the scene. Note that the `fmod()` function in `MSL` uses `trunc()` instead of `floor()` so we need to create a custom __mod__ operator here because we also want to use the negative values, so we use the `GLSL` specification for `mod()` which is `x - y * floor(x/y)`. We need the `modulus` operator to draw many small rectangles mirrored on a distance of __0.1__ from each other. Finally, we use these functions to generate a shape that looks a bit like a tall building with windows:

{% highlight swift %}kernel void compute(texture2d&lt;float, access::write&gt; output [[texture(0)]],
                    constant float &amp;timer [[buffer(0)]],
                    uint2 gid [[thread_position_in_grid]])
{
    int width = output.get_width();
    int height = output.get_height();
    float2 uv = float2(gid) / float2(width, height);
    uv = uv * 2.0 - 1.0;
    float d2scene = distanceToScene(uv);
    bool i = d2scene &lt; 0.0;
    float4 color = i ? float4( .1, .5, .5, 1. ) : float4( .7, .8, .8, 1. );
    output.write(color, gid);
}
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_1.png &quot;1&quot;)

For shadows to work we need to first - get the distance to the light, second - get the direction to the light, and third - step in that direction until we either reach the light or hit an object. So let's create a light at position __lightPos__ which we will animate for fun. We use that good old __timer__ uniform that we have it handy passed from the host (`API`) code. Then, we get the distance from any given point to `lightPos` and then just color the pixel based on the distance from the light - if not inside an object. We want the color to be lighter closer to the light and darker when further away. We use the `max()` function to avoid negative values for the brightness of the light. Replace the last line in the kernel with the lines below:
  
{% highlight swift %}float2 lightPos = float2(1.3 * sin(timer), 1.3 * cos(timer));
float dist2light = length(lightPos - uv);
color *= max(0.0, 2. - dist2light );
output.write(color, gid);
{% endhighlight %}  

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_2.png &quot;2&quot;)

We did the first two steps (light position and direction) so let's proceed to doing the third one - the actual shadow function:

{% highlight swift %}float getShadow(float2 point, float2 lightPos) {
    float2 lightDir = lightPos - point;
    float dist2light = length(lightDir);
    for (float i=0.; i &lt; 300.; i++) {
        float distAlongRay = dist2light * (i / 300.);
        float2 currentPoint = point + lightDir * distAlongRay;
        float d2scene = distanceToScene(currentPoint);
        if (d2scene &lt;= 0.) { return 0.; }
    }
    return 1.;
} 
{% endhighlight %}

Let's go over the code, line by line. We first get the direction from the point to the light. Next, we find the distance to the light so we know how far we need to move along this light ray. Then, we use a loop to divide the ray into many smaller steps. If we don't use enough steps, we might jump past our object and that would leave &quot;holes&quot; in the shadow. Next, we calculate how far along the ray we are currently and move along the ray by this distance to find the point in space we're sampling at. Then, we see how far we are from the surface at that point and then test if we are inside an object. If we are, return __0__ because we are in the shadow, otherwise return __1__ as the ray did not hit any object. It is finally time to see some shadows! In the kernel, replace the last line with the lines below:

{% highlight swift %}float shadow = getShadow(uv, lightPos);
shadow = shadow * 0.5 + 0.5;
color *= shadow;
output.write(color, gid);
{% endhighlight %}

We use the value __0.5__ to attenuate the effect of the shadow, however, feel free to play with various values and notice how it affects itc. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_3.png &quot;3&quot;)

Right now the loop goes in one-pixel steps which is not good performance-wise. We can improve that a little by accelerating the steps along the ray. We don't need to move in really small steps. We can move in big steps so long as we don't step past our object. We can safely step in _any_ direction by the distance to the scene instead of a fixed step size, and this way we skip over empty areas really fast! When finding the distance to the nearest surface, we don't know what direction the surface is in so in fact we have the _radius_ of a circle that intersects with the nearest part of the scene. We can trace along the ray, always stepping to the edge of the circle, until the circle radius becomes __0__ which means it intersected a surface. Oh, right, this is the __raymarching__ technique we learned about last time! Simply replace the content of the __getShadow()__ function with the lines below:

{% highlight swift %}float2 lightDir = normalize(lightPos - point);
float dist2light = length(lightDir);
float distAlongRay = 0.0;
for (float i=0.0; i &lt; 80.; i++) {
    float2 currentPoint = point + lightDir * distAlongRay;
    float d2scene = distanceToScene(currentPoint);
    if (d2scene &lt;= 0.001) { return 0.0; }
    distAlongRay += d2scene;
    if (distAlongRay &gt; dist2light) { break; }
}
return 1.;
{% endhighlight %}
 
In `raymarching` the size of the step depends on the distance from the surface. In empty areas it jumps big distances and it can travel a long way. But if it’s parallel to the object and close to it, the distance is always small so the jump size is also small. That means the ray travels very slowly. With a fixed number of steps, it doesn’t travel far. With __80__ or more steps we should be safe from getting &quot;holes&quot; in the shadow. If you run the playground again the output looks similar except the shadow is faster now. To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/lt3SzB&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

This type of shadows is called `hard shadows`. Next time we will be looking into `soft shadows` which are more realistic and better looking. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">A quite important topic in Computer Graphics is lighting and shadows. This will be a first episode from a multi-part series about Shadows in Metal. We are going to work on the playground we used in Using metal part 15 and build up on that. Let’s set up a basic scene:</summary></entry><entry><title type="html">Raymarching in Metal</title><link href="http://localhost:4000/2016/12/30/raymarching-in-metal.html" rel="alternate" type="text/html" title="Raymarching in Metal" /><published>2016-12-30T00:00:00-06:00</published><updated>2016-12-30T00:00:00-06:00</updated><id>http://localhost:4000/2016/12/30/raymarching-in-metal</id><content type="html" xml:base="http://localhost:4000/2016/12/30/raymarching-in-metal.html">__Raymarching__ is a fast rendering method used in realtime graphics. The geometry is usually not passed to the renderer but rather created in the shader using __Signed Distance Fields (SDF)__ functions that describe the shortest distance between a point and the surface of any object in the scene. The `SDF` returns a negative number if the point is inside of an object. Also, `SDFs` are useful because they allow us to reduce the number of samples used by `Ray Tracing`.  Similar to _Ray Tracing_, in `Raymarching` we also have a ray cast for each pixel on the view plane and each ray is used to determine if there is an intersection with an object. 

The difference between the two techniques is that in _Ray Tracing_ the intersection is determined by a strict set of equations while in `Raymarching` the intersection is approximated. Using `SDFs` we can _march_ along the ray until we get close enough to an object. This is inexpensive to compute compared to exactly determining intersections which could become very expensive when there are many objects in the scene and the lighting is complex. Another great use case for `Raymarching` is volumetric rendering (fog, water, clouds) which _Ray Tracing_ cannot easily do because determining intersections with such volumes is quite difficult.

To follow allong, you can use the playground from [Using MetalKit part 10](http://metalkit.org/2016/05/02/using-metalkit-part-10.html), slightly modified as explained next. Let’s start with two basic building blocks we need at the very minimum in our kernel: a ray and an object (sphere).

{% highlight swift %}struct Ray {
    float3 origin;
    float3 direction;
    Ray(float3 o, float3 d) {
        origin = o;
        direction = d;
    }
};

struct Sphere {
    float3 center;
    float radius;
    Sphere(float3 c, float r) {
        center = c;
        radius = r;
    }
};
{% endhighlight %}

As we did back in _part 10_, let's also write a `SDF` for calculating the distance from a given point to the sphere. The difference from the old function is that now our point is _marching_ along the ray, so we use the ray position instead:

{% highlight swift %}float distToSphere(Ray ray, Sphere s) {
    return length(ray.origin - s.center) - s.radius;
}
{% endhighlight %}

All we had to do back then was to calculate the distance from any given point to a circle (not a sphere because we did not have `3D` back then) like this:

{% highlight swift %}float dist(float2 point, float2 center, float radius) {
    return length(point - center) - radius;
}

...
float distToCircle = dist(uv, float2(0.), 0.5);
bool inside = distToCircle &lt; 0.;
output.write(inside ? float4(1.) : float4(0.), gid);
...
{% endhighlight %}

We now need to have a ray and march along with it through the scene, so replace those last three lines in the kernel with the following lines:

{% highlight swift %}Sphere s = Sphere(float3(0.), 1.);
Ray ray = Ray(float3(0., 0., -3.), normalize(float3(uv, 1.0)));
float3 col = float3(0.);
for (int i=0.; i&lt;100.; i++) {
    float dist = distToSphere(ray, s);
    if (dist &lt; 0.001) {
        col = float3(1.);
        break;
    }
    ray.origin += ray.direction * dist;
}
output.write(float4(col, 1.), gid);
{% endhighlight %}

Let's go over the code line by line. We first create a sphere object and a ray. Notice that as ray's `z` value approaches `0`, the sphere seems bigger because the ray is closer to the scene, and vice versa, when it goes away from `0`, the sphere seems smaller for the obvious reason -- we use our ray as our implicit `camera`. Next we define the color to be initially a solid black. Now comes the very essence of `raymarching`! We loop for a given number of times (steps) to make sure we get enough precision. We go with `100` in this case but you can try with a bigger number of steps and see how the quality of the rendered image improves, at the expense of more computing resources used, however. Inside the loop we calculate the distance from our current position along the ray to the scene, while also checking if we reached an object in the scene, and if we did, we color it in solid white and break out of this particular iteration, or otherwise update the ray position by moving it closer to the scene. 

Notice that we normalized the ray direction to cover edge cases where for example the length of the vector `(1, 1, 1)` (corner of the screen) would have a value of `sqrt(1 * 1 + 1 * 1 + 1 * 1)` which approximates to `1.73`. That means we would need to move the ray position forward by `1.73 * dist` which is almost double the distance we need to move forward, thus making us miss the object by overshooting the ray beyond the intersection point. For that reason, we normalize the direction, to make sure its length will always be `1`. Finally, we write the color to the output texture. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/raymarching1.png &quot;1&quot;)

Now let's create a function named __distToScene__ that only takes a ray in as argument because all we care now is to find the shortest distance to a complex scene that contains multiple objects. Next, we move the code related to the sphere inside this new function where we return only the distance to the sphere (for now). Then, we change the sphere position to `(1, 1, 1)` and its radius to `0.5` which means the sphere is now in the `0.5 ... 1.5` range. Here comes a neat trick to do instancing: if we repeat the space between `0.0 ... 2.0`, the sphere is safely inside. Next, we make a local copy of the ray and modulus its origin. Then we use the repeating ray with the `distToSphere()` function. 

{% highlight swift %}float distToScene(Ray r) {
    Sphere s = Sphere(float3(1.), 0.5);
    Ray repeatRay = r;
    repeatRay.origin = fmod(r.origin, 2.0);
    return distToSphere(repeatRay, s);
}
{% endhighlight %}

By using the `fmod` function we repeated the space throughout the entire screen and pratically created an infinite number of spheres, each with its own (repeated) ray. Of course, we will only see the ones bounded by the `x` and `y` coordinates of the screen, however, the `z` coordinate will let us see how the spheres go indefinitely in depth. Inside the kernel, remove the sphere line, move the ray to a really far location, modify `dist` to rather give us the distance to the scene, and finally change the last line to give us some nice colors:

{% highlight swift %}Ray ray = Ray(float3(1000.), normalize(float3(uv, 1.0)));
...
float dist = distToScene(ray);
...
output.write(float4(col * abs((ray.origin - 1000.) / 10.0), 1.), gid);
{% endhighlight %}

We are multiplying the color by the ray position. We divide by `10.0` because the scene is quite big and the ray position is bigger than `1.0` in most places, which would give us a solid white. We use `abs()` because on the left side of the screen `x` is lower than `0` which would give us a solid black so we basically mirror the top/bottom and left/right colors. Finally, we offset the ray position by `1000` to match the ray origin (camera) we set. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/raymarching2.png &quot;2&quot;)

Next, let's animate the scene! We have seen in [part 12](http://metalkit.org/2016/05/18/using-metalkit-part-12.html) how to send useful _uniforms_ to the `GPU`, such as the `time` so we are not going to discuss about how to implement that again here.

{% highlight swift %}float3 camPos = float3(1000. + sin(time) + 1., 1000. + cos(time) + 1., time);
Ray ray = Ray(camPos, normalize(float3(uv, 1.)));
...
float3 posRelativeToCamera = ray.origin - camPos;
output.write(float4(col * abs((posRelativeToCamera) / 10.0), 1.), gid);
{% endhighlight %}

We added `time` to all three coordinates, but we only fluctuate the `x` and `y` while keeping `z` a straight line. The `1.` part is there just to stop the camera crashing into the nearest sphere. To see an animated version of this code, I used a `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/XtcSDf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;
    
I want to thanks [Chris](https://twitter.com/_psonice) again for his assistance. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Raymarching is a fast rendering method used in realtime graphics. The geometry is usually not passed to the renderer but rather created in the shader using Signed Distance Fields (SDF) functions that describe the shortest distance between a point and the surface of any object in the scene. The SDF returns a negative number if the point is inside of an object. Also, SDFs are useful because they allow us to reduce the number of samples used by Ray Tracing.  Similar to Ray Tracing, in Raymarching we also have a ray cast for each pixel on the view plane and each ray is used to determine if there is an intersection with an object.</summary></entry><entry><title type="html">Beginning Metal - a new course</title><link href="http://localhost:4000/2016/11/30/new-metal-course.html" rel="alternate" type="text/html" title="Beginning Metal - a new course" /><published>2016-11-30T00:00:00-06:00</published><updated>2016-11-30T00:00:00-06:00</updated><id>http://localhost:4000/2016/11/30/new-metal-course</id><content type="html" xml:base="http://localhost:4000/2016/11/30/new-metal-course.html">Our new website is completely revamped as you can see while navigating through the posts. The good news don't stop here. [Caroline](https://twitter.com/carolinebegbie), a good friend of mine and an awesome `Metal` programmer, just launched her new video course - [Beginning Metal](https://videos.raywenderlich.com/courses/beginning-metal/lessons/1) - through the `RayWenderlich.com` website. The first `2` lessons are free, however, to watch the remaining `13` videos you'd need to purchase membership for at least one month. Each of the lessons provide the sample code used in the videos as well as challenges that you would want to solve preferably before moving on to the next lesson. At the time of writing this post, there are only `2` more videos left to be released.

The course starts with the very basics of 3D graphics, learning what the GPU does and what the graphics pipeline is. The next couple of chapters teach you how to render in 2D - your first triangle. Then, you learn about the Metal Shading Language and the shader functions - why they run on the GPU, see how they fit into the pipeline, and how to position and color vertices. Next, you’ll learn how to map textures to your geometry to make your graphics look even greater. The next couple of chapters take you through the transformation matrices to prepare you for the transition from `2D` to `3D`. Next, you'll learn about the `Model I/O` framework and how you can easily import models from modeling programs. The next couple of chapters teach you all about basic lighting using the Phong shading model. Another couple of chapters are dedicated to learning how to build a simple game using everything you've learned. The final chapter summarizes everything. 

I was absolutely impressed by the high quality of this course - quality which is actually the norm at `RayWenderlich.com` to be honest. The course teaches the total beginner as well as the more advanced Metal programmer to adopt the best practices for coding in Swift and Metal. The code builds up on previous chapters and in the end you have a minimal game engine that is fully functional and makes you crave for more Metal content in future courses. And I hope they do.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Our new website is completely revamped as you can see while navigating through the posts. The good news don’t stop here. Caroline, a good friend of mine and an awesome Metal programmer, just launched her new video course - Beginning Metal - through the RayWenderlich.com website. The first 2 lessons are free, however, to watch the remaining 13 videos you’d need to purchase membership for at least one month. Each of the lessons provide the sample code used in the videos as well as challenges that you would want to solve preferably before moving on to the next lesson. At the time of writing this post, there are only 2 more videos left to be released.

The course starts with the very basics of 3D graphics, learning what the GPU does and what the graphics pipeline is. The next couple of chapters teach you how to render in 2D - your first triangle. Then, you learn about the Metal Shading Language and the shader functions - why they run on the GPU, see how they fit into the pipeline, and how to position and color vertices. Next, you’ll learn how to map textures to your geometry to make your graphics look even greater. The next couple of chapters take you through the transformation matrices to prepare you for the transition from 2D to 3D. Next, you’ll learn about the Model I/O framework and how you can easily import models from modeling programs. The next couple of chapters teach you all about basic lighting using the Phong shading model. Another couple of chapters are dedicated to learning how to build a simple game using everything you’ve learned. The final chapter summarizes everything.

I was absolutely impressed by the high quality of this course - quality which is actually the norm at RayWenderlich.com to be honest. The course teaches the total beginner as well as the more advanced Metal programmer to adopt the best practices for coding in Swift and Metal. The code builds up on previous chapters and in the end you have a minimal game engine that is fully functional and makes you crave for more Metal content in future courses. And I hope they do.

Until next time!</summary></entry><entry><title type="html">Using MetalKit part 2*3^2</title><link href="http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2.html" rel="alternate" type="text/html" title="Using MetalKit part 2*3^2" /><published>2016-10-01T00:00:00-05:00</published><updated>2016-10-01T00:00:00-05:00</updated><id>http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2</id><content type="html" xml:base="http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2.html">Yes, as the title suggests, we're going to have another of those posts with math (and fun) in it. I was thinking the other day, what can we do while commuting for an hour or so, without internet and possibly without a laptop as well, just carrying an `iPad` with us. Luckily, the `iPad` now has the awesome `Swift Playgrounds` app.

Let's start with a new playground that runs a basic compute kernel. Since the current version of the `Swift Playgrounds` app does not yet let us edit the `Auxiliary Source Files`, where all our `Swift` and `Metal` files usually reside, we will have to write our code in the main playground page, but it is not that complicated. All we have to do is modify our `MetalView` initializer and let it take in an extra argument -- our shader/kernel code. Then we start building our code by adding more lines to this long string.

Let's start with a light blue sky background color:

{% highlight swift %}let shader =
&quot;#include &lt;metal_stdlib&gt;\n&quot; +
&quot;using namespace metal;&quot; +
&quot;kernel void k(texture2d&lt;float,access::write&gt; o[[texture(0)]],&quot; +
&quot;              uint2 gid[[thread_position_in_grid]]) {&quot; +
&quot;   float3 color = float3(0.5, 0.8, 1.0);&quot; +
&quot;   o.write(float4(color, 1.0), gid);&quot; +
&quot;}&quot;
{% endhighlight %}

If you run the playground now, the output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_1.png &quot;1&quot;)

Next, let's draw a gradient. we divide the current pixel coordinates to the screen dimensions and we get __UV__ -- a pair of floats between __(0-1)__. we then multiply the fixed color with __Y__ -- the vertical component of `UV` which gives us the gradient:

{% highlight swift %}&quot;   int width = o.get_width();&quot; +
&quot;   int height = o.get_height();&quot; +
&quot;   float2 uv = float2(gid) / float2(width, height);&quot; +
&quot;   color *= uv.y;&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_2.png &quot;2&quot;)

Let's work on a nicer background next. A smooth gradient would look like a great sunset. We can use __mix__ to blend colors. We tell the function to blend vertically, and take the complement of __Y__ to switch the colors:

{% highlight swift %}&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_3.png &quot;3&quot;)

From here we could go to drawing a black hole. We would achieve that by using a distance function (__length__) to draw black in the middle of the screen __(0.5, 0.5)__ and add more and more background color outside of it, until we reach the maximum value in the screen corners. Replace the last line with:

{% highlight swift %}&quot;   float2 q = uv - float2(0.5);&quot; +
&quot;   color *= length(q);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_4.png.png &quot;4&quot;)

Next we use __smootstep__ to draw a round shape that is black inside, blue outside and a blended color between __r__ and __(r + 0.01)__. Replace the last line with:

{% highlight swift %}&quot;   float r = 0.2;&quot; +
&quot;   color *= smoothstep(r, r + 0.01, length(q));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_5.png &quot;5&quot;)

If we're not satisfied with a circular perimeter, we could make it _bumpy_ by using math functions such as __cos__ and __atan2__. We generate here __9__ spikes (__frequency__) with a spike length (__amplitude__) of __0.1__:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_6.png &quot;6&quot;)

Adding the __X__ coordinate to the _cosine_ phase introduces a spike _bend-like_ effect:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_7.png &quot;7&quot;)

You can rotate them by adding a small number such as __1.0__ to the _cosine_ value:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x + 1.0);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_8.png &quot;8&quot;)

If you think this is starting to look like a palm tree canopy, I see it too! We can draw its trunk using __abs__ which gives us horizontal/vertical distances instead of _euclidian_ distances (to a given point) like _length_ did, so let's take the __X__ distance and add these lines (we are reusing both __r__ and __color__) after the existing ones: 

{% highlight swift %}&quot;   r = 0.015;&quot; +
&quot;   color *= smoothstep(r, r + 0.002, abs(q.x));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_9.png &quot;9&quot;)

We can remove the unneeded part of the trunk by using another __smoothstep__ on the __Y__ coordinate:

{% highlight swift %}&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x))) * smoothstep(0.0, 0.1, q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_10.png &quot;10&quot;)

Since both the canopy and trunk are using __q__, modifying its value will move both:

{% highlight swift %}&quot;   float2 q = uv - float2(0.67, 0.29);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_11.png &quot;11&quot;)

By introducing a __sin__ function we can bend the trunk. A too small _frequency_ does not bend it enough while a too high _frequency_ bends it too much so __2.0__ seems right. An _amplitude_ of __0.25__ also moves the base of the trunk towards the edge of the screen so it looks right (as an aside, changing the sign from __+__ to __--__ will shift the base to the other side):

{% highlight swift %}&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x - 0.25 * sin(2.0 * q.y)))) * smoothstep(0.0, 0.1, q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_12.png &quot;12&quot;)

The trunk, however, is too smooth. To add irregularities to its surface we use __cos__ again. A high _frequency_ and low _amplitude_ seem to be what we need to make it look right:

{% highlight swift %}&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_13.png &quot;13&quot;)

Also, trunks are usually shaping the ground a little around their base, so an __exp__ function is what we need here because it grows slowly in the beginning and then it soars to the skies. We use an _attenuation_ factor of __-50.0__:

{% highlight swift %}&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y) + exp(-50.0 * (1.0 - uv.y));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_14.png &quot;14&quot;)

We can increase the presence of the second color by using __sqrt__ which gives us bigger numbers (when used on sub-unitary numbers) to work with. The sunset is about to end soon:

{% highlight swift %}&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +
{% endhighlight %}

The final image on the iPad should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_15.png &quot;15&quot;)

In conclusion, we saw how to use __sqrt__ to shape transitions, then __cos__ to create variations of ups and downs in shapes, then __exp__ that allows us to create curves, then __smoothstep__ for thresholding, then __abs__ for symmetry and __mix__ for blending. Still commuting? Why don't you take a look at how this nice clover was created:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_16.png &quot;16&quot;)

I want to say thanks to [Inigo Quilez](https://twitter.com/iquilezles) again, for keep inspiring me to write more and more about drawing with math. All the math in this tutorial belongs to him. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Yes, as the title suggests, we’re going to have another of those posts with math (and fun) in it. I was thinking the other day, what can we do while commuting for an hour or so, without internet and possibly without a laptop as well, just carrying an iPad with us. Luckily, the iPad now has the awesome Swift Playgrounds app.

Let’s start with a new playground that runs a basic compute kernel. Since the current version of the Swift Playgrounds app does not yet let us edit the Auxiliary Source Files, where all our Swift and Metal files usually reside, we will have to write our code in the main playground page, but it is not that complicated. All we have to do is modify our MetalView initializer and let it take in an extra argument – our shader/kernel code. Then we start building our code by adding more lines to this long string.

Let’s start with a light blue sky background color:

let shader =
&quot;#include &amp;lt;metal_stdlib&amp;gt; &quot; +
&quot;using namespace metal;&quot; +
&quot;kernel void k(texture2d&amp;lt;float,access::write&amp;gt; o[[texture(0)]],&quot; +
&quot;              uint2 gid[[thread_position_in_grid]]) {&quot; +
&quot;   float3 color = float3(0.5, 0.8, 1.0);&quot; +
&quot;   o.write(float4(color, 1.0), gid);&quot; +
&quot;}&quot;

If you run the playground now, the output image should look like this:



Next, let’s draw a gradient. we divide the current pixel coordinates to the screen dimensions and we get UV – a pair of floats between (0-1). we then multiply the fixed color with Y – the vertical component of UV which gives us the gradient:

&quot;   int width = o.get_width();&quot; +
&quot;   int height = o.get_height();&quot; +
&quot;   float2 uv = float2(gid) / float2(width, height);&quot; +
&quot;   color *= uv.y;&quot; +

The output image should look like this:



Let’s work on a nicer background next. A smooth gradient would look like a great sunset. We can use mix to blend colors. We tell the function to blend vertically, and take the complement of Y to switch the colors:

&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +

The output image should look like this:



From here we could go to drawing a black hole. We would achieve that by using a distance function (length) to draw black in the middle of the screen (0.5, 0.5) and add more and more background color outside of it, until we reach the maximum value in the screen corners. Replace the last line with:

&quot;   float2 q = uv - float2(0.5);&quot; +
&quot;   color *= length(q);&quot; +

The output image should look like this:



Next we use smootstep to draw a round shape that is black inside, blue outside and a blended color between r and (r + 0.01). Replace the last line with:

&quot;   float r = 0.2;&quot; +
&quot;   color *= smoothstep(r, r + 0.01, length(q));&quot; +

The output image should look like this:



If we’re not satisfied with a circular perimeter, we could make it bumpy by using math functions such as cos and atan2. We generate here 9 spikes (frequency) with a spike length (amplitude) of 0.1:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0);&quot; +

The output image should look like this:



Adding the X coordinate to the cosine phase introduces a spike bend-like effect:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x);&quot; +

The output image should look like this:



You can rotate them by adding a small number such as 1.0 to the cosine value:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x + 1.0);&quot; +

The output image should look like this:



If you think this is starting to look like a palm tree canopy, I see it too! We can draw its trunk using abs which gives us horizontal/vertical distances instead of euclidian distances (to a given point) like length did, so let’s take the X distance and add these lines (we are reusing both r and color) after the existing ones:

&quot;   r = 0.015;&quot; +
&quot;   color *= smoothstep(r, r + 0.002, abs(q.x));&quot; +

The output image should look like this:



We can remove the unneeded part of the trunk by using another smoothstep on the Y coordinate:

&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x))) * smoothstep(0.0, 0.1, q.y);&quot; +

The output image should look like this:



Since both the canopy and trunk are using q, modifying its value will move both:

&quot;   float2 q = uv - float2(0.67, 0.29);&quot; +

The output image should look like this:



By introducing a sin function we can bend the trunk. A too small frequency does not bend it enough while a too high frequency bends it too much so 2.0 seems right. An amplitude of 0.25 also moves the base of the trunk towards the edge of the screen so it looks right (as an aside, changing the sign from + to – will shift the base to the other side):

&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x - 0.25 * sin(2.0 * q.y)))) * smoothstep(0.0, 0.1, q.y);&quot; +

The output image should look like this:



The trunk, however, is too smooth. To add irregularities to its surface we use cos again. A high frequency and low amplitude seem to be what we need to make it look right:

&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y);&quot; +

The output image should look like this:



Also, trunks are usually shaping the ground a little around their base, so an exp function is what we need here because it grows slowly in the beginning and then it soars to the skies. We use an attenuation factor of -50.0:

&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y) + exp(-50.0 * (1.0 - uv.y));&quot; +

The output image should look like this:



We can increase the presence of the second color by using sqrt which gives us bigger numbers (when used on sub-unitary numbers) to work with. The sunset is about to end soon:

&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +

The final image on the iPad should look like this:



In conclusion, we saw how to use sqrt to shape transitions, then cos to create variations of ups and downs in shapes, then exp that allows us to create curves, then smoothstep for thresholding, then abs for symmetry and mix for blending. Still commuting? Why don’t you take a look at how this nice clover was created:



I want to say thanks to Inigo Quilez again, for keep inspiring me to write more and more about drawing with math. All the math in this tutorial belongs to him. The source code is posted on Github as usual.

Until next time!</summary></entry><entry><title type="html">Using MetalKit part 17</title><link href="http://localhost:4000/2016/09/24/using-metalkit-part-17.html" rel="alternate" type="text/html" title="Using MetalKit part 17" /><published>2016-09-24T00:00:00-05:00</published><updated>2016-09-24T00:00:00-05:00</updated><id>http://localhost:4000/2016/09/24/using-metalkit-part-17</id><content type="html" xml:base="http://localhost:4000/2016/09/24/using-metalkit-part-17.html">I am writing this article for three reasons: first, to tell you that I am working on updating all the `Metal` code to `Swift 3` and then moving the tutorials to a new home with a nicer design and a proper domain name; second, I wanted to show you a different way to work with `MetalKit` other than subclassing `MTKView`, that is, using the `MTKViewDelegate`; and third, I wanted to answer one of our readers' question about how to draw wireframes.

Let's start by using the code from `Part 4` which is an `Xcode` project but we will turn it into a playground this time. This is going to be a shockingly short tutorial but all you have to do is add the following line right before encoding the draw command:

{% highlight swift %}renderEncoder.setTriangleFillMode(.lines)
{% endhighlight %}

That's it! Run the playground and enjoy the wireframed triangle. If you don't want it to have an interpolated color, in the fragment shader also replace the return line with a constant color like green, for example:

{% highlight swift %}return half4(0.0, 1.0, 0.0, 1.0);
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter17.png &quot;2D&quot;)

For a `3D` rendering there is one more thing we need to do, disable the backface culling. If you're working in the playground from `Part 9` just comment out this line:

{% highlight swift %}commandEncoder.setCullMode(.back)
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter17_2.png &quot;3D&quot;)

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">I am writing this article for three reasons: first, to tell you that I am working on updating all the Metal code to Swift 3 and then moving the tutorials to a new home with a nicer design and a proper domain name; second, I wanted to show you a different way to work with MetalKit other than subclassing MTKView, that is, using the MTKViewDelegate; and third, I wanted to answer one of our readers’ question about how to draw wireframes.

Let’s start by using the code from Part 4 which is an Xcode project but we will turn it into a playground this time. This is going to be a shockingly short tutorial but all you have to do is add the following line right before encoding the draw command:

renderEncoder.setTriangleFillMode(.lines)

That’s it! Run the playground and enjoy the wireframed triangle. If you don’t want it to have an interpolated color, in the fragment shader also replace the return line with a constant color like green, for example:

return half4(0.0, 1.0, 0.0, 1.0);

The output image should look like this:



For a 3D rendering there is one more thing we need to do, disable the backface culling. If you’re working in the playground from Part 9 just comment out this line:

commandEncoder.setCullMode(.back)

The output image should look like this:



The source code is posted on Github as usual.

Until next time!</summary></entry></feed>
