<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-05-01T09:25:09-05:00</updated><id>http://localhost:4000//</id><title type="html">The Metal Framework</title><subtitle>Resources and tutorials for Metal, MetalKit and Metal Performance Shaders.
</subtitle><entry><title type="html">Working with memory in Metal</title><link href="http://localhost:4000/2017/04/30/working-with-memory-in-metal.html" rel="alternate" type="text/html" title="Working with memory in Metal" /><published>2017-04-30T00:00:00-05:00</published><updated>2017-04-30T00:00:00-05:00</updated><id>http://localhost:4000/2017/04/30/working-with-memory-in-metal</id><content type="html" xml:base="http://localhost:4000/2017/04/30/working-with-memory-in-metal.html">&lt;p&gt;Today we look at how memory is managed when working with the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; framework defines memory sources as &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLBuffer&lt;/code&gt; objects which are typeless and unformatted allocations of memory (any type of data), and &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLTexture&lt;/code&gt; objects which are formatted allocations of memory holding image data. We only look at buffers in this article.&lt;/p&gt;

&lt;p&gt;To create &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLBuffer&lt;/code&gt; objects we have 3 options:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;makeBuffer(length:options:)&lt;/strong&gt; creates a &lt;code class=&quot;highlighter-rouge&quot;&gt;MTLBuffer&lt;/code&gt; object with a new allocation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;makeBuffer(bytes:length:options:)&lt;/strong&gt; copies data from an existing allocation into a new allocation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;makeBuffer(bytesNoCopy:length:options:deallocator:)&lt;/strong&gt; reuses an existing storage allocation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Letâ€™s create a couple of buffers and see how data is being sent to the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; and then sent back to the &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt;. We first create a buffer for both input and output data and initialize them to some values:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;myVector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;repeating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MemoryLayout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;outBuffer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myVector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;enumerated&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;inBuffer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The new &lt;strong&gt;MemoryLayout&amp;lt; Type &amp;gt;.stride&lt;/strong&gt; syntax was introduced in &lt;code class=&quot;highlighter-rouge&quot;&gt;Swift 3&lt;/code&gt; to replace the old &lt;code class=&quot;highlighter-rouge&quot;&gt;strideof(Type)&lt;/code&gt; function. By the way, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;.stride&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;.size&lt;/code&gt; for memory alignment reasons. The &lt;strong&gt;stride&lt;/strong&gt; is the number of bytes moved when a pointer is incremented. The next step is to tell the command encoder about our buffers:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: the Metal Best Practices Guide states that we should always avoid creating buffers when our data is less than &lt;strong&gt;4 KB&lt;/strong&gt; (up to a thousand &lt;code class=&quot;highlighter-rouge&quot;&gt;Floats&lt;/code&gt;, for example). In this case we should simply use the &lt;strong&gt;setBytes()&lt;/strong&gt; function instead of creating a buffer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The final step is to read the data the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; sent back by using the &lt;strong&gt;contents()&lt;/strong&gt; function to bind the memory data to our output buffer:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bindMemory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;repeating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;..&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Metal&lt;/code&gt; resources must be configured for fast memory access and driver performance optimizations. Resource &lt;strong&gt;storage modes&lt;/strong&gt; let us define the storage location and access permissions for our buffers and textures. If you take a look above where we created our buffers, we used the default option (&lt;strong&gt;[]&lt;/strong&gt;) as the storage mode.&lt;/p&gt;

&lt;p&gt;All &lt;code class=&quot;highlighter-rouge&quot;&gt;iOS&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tvOS&lt;/code&gt; devices support a &lt;em&gt;unified memory model&lt;/em&gt; where both the &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; share the system memory, while &lt;code class=&quot;highlighter-rouge&quot;&gt;macOS&lt;/code&gt; devices support a &lt;em&gt;discrete memory model&lt;/em&gt; where the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; has its own memory. In &lt;code class=&quot;highlighter-rouge&quot;&gt;iOS&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tvOS&lt;/code&gt;, the &lt;strong&gt;Shared&lt;/strong&gt; mode (&lt;code class=&quot;highlighter-rouge&quot;&gt;MTLStorageModeShared&lt;/code&gt;) defines system memory accessible to both &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt;, while &lt;strong&gt;Private&lt;/strong&gt; mode (&lt;code class=&quot;highlighter-rouge&quot;&gt;MTLStorageModePrivate&lt;/code&gt;) defines system memory accessible only to the GPU. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Shared&lt;/code&gt; mode is the default storage mode on all three operating systems.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://developer.apple.com/library/content/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/Art/ResourceManagement_iOStvOSMemory_2x.png&quot; alt=&quot;alt text&quot; title=&quot;iOS and tvOS&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Besides these two storage modes, &lt;code class=&quot;highlighter-rouge&quot;&gt;macOS&lt;/code&gt; also has a &lt;strong&gt;Managed&lt;/strong&gt; mode (&lt;code class=&quot;highlighter-rouge&quot;&gt;MTLStorageModeManaged&lt;/code&gt;) that defines a synchronized memory pair for a resource, with one copy in system memory and another in video memory for faster CPU and GPU local accesses.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://developer.apple.com/library/content/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/Art/ResourceManagement_OSXMemory_2x.png&quot; alt=&quot;alt text&quot; title=&quot;macOS&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now letâ€™s look at what happens on the &lt;code class=&quot;highlighter-rouge&quot;&gt;GPU&lt;/code&gt; when we send it data buffers. Here is a typical vertex shader example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Vertices&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vertex_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Vertices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]],&lt;/span&gt; 
            		    &lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Uniforms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniforms&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]],&lt;/span&gt; 
            		    &lt;span class=&quot;n&quot;&gt;uint&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vid&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Metal Shading Language&lt;/code&gt; implements address space qualifiers to specify the region of memory where a function variable or argument is allocated:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;device&lt;/strong&gt; - refers to buffer memory objects allocated from the device memory pool that are both readable and writeable unless the keyword &lt;strong&gt;const&lt;/strong&gt; preceeds it in which case the objects are only readable.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;constant&lt;/strong&gt; - refers to buffer memory objects allocated from the device memory pool but that are &lt;code class=&quot;highlighter-rouge&quot;&gt;read-only&lt;/code&gt;. Variables in program scope must be declared in the constant address space and initialized during the declaration statement. The constant address space is optimized for multiple instances executing a graphics or kernel function accessing the same location in the buffer.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;threadgroup&lt;/strong&gt; - is used to allocate variables used by a kernel functions only and they are allocated for each threadgroup executing the kernel, are shared by all threads in a threadgroup and exist only for the lifetime of the threadgroup that is executing the kernel.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;thread&lt;/strong&gt; - refers to the per-thread memory address space. Variables allocated in this address space are not visible to other threads. Variables declared inside a graphics or kernel function are allocated in the thread address space.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a bonus, letâ€™s also look at another way of accessing memory locations in &lt;code class=&quot;highlighter-rouge&quot;&gt;Swift 3&lt;/code&gt;. This code snippet belongs to a previous article, &lt;a href=&quot;http://metalkit.org/2016/08/30/the-model-i-o-framework.html&quot;&gt;The Model I/O framework&lt;/a&gt;, so we will not go again into details about voxels. Just think of an array that we need to iterate over to get values:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bundle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forResource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;teapot&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;withExtension&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;obj&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;asset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MDLAsset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;voxelArray&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MDLVoxelArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;asset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;divisions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;patchRadius&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxelArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;voxelIndices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;withUnsafeBytes&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;voxels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UnsafePointer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;MDLVoxelIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Void&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MemoryLayout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;MDLVoxelIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxelArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;spatialLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ofIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pointee&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case, the &lt;code class=&quot;highlighter-rouge&quot;&gt;MDLVoxelArray&lt;/code&gt; object has a function named &lt;code class=&quot;highlighter-rouge&quot;&gt;spatialLocation()&lt;/code&gt; which lets us iterate through the array by using an &lt;code class=&quot;highlighter-rouge&quot;&gt;UnsafePointer&lt;/code&gt; of the &lt;code class=&quot;highlighter-rouge&quot;&gt;MDLVoxelIndex&lt;/code&gt; type and accessing the data through the &lt;code class=&quot;highlighter-rouge&quot;&gt;pointee&lt;/code&gt; at each location. In this example we are only printing out the first value found at that address but a simple loop will let us get all of them like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;voxelIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxels&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxelArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;spatialLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ofIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxelIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pointee&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;voxelIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voxelIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;successor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/MetalKit/metal&quot;&gt;source code&lt;/a&gt; is posted on &lt;code class=&quot;highlighter-rouge&quot;&gt;Github&lt;/code&gt; as usual.&lt;/p&gt;

&lt;p&gt;Until next time!&lt;/p&gt;</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Today we look at how memory is managed when working with the GPU. The Metal framework defines memory sources as MTLBuffer objects which are typeless and unformatted allocations of memory (any type of data), and MTLTexture objects which are formatted allocations of memory holding image data. We only look at buffers in this article.</summary></entry><entry><title type="html">Ambient Occlusion in Metal</title><link href="http://localhost:4000/2017/03/22/ambient-occlusion-in-metal.html" rel="alternate" type="text/html" title="Ambient Occlusion in Metal" /><published>2017-03-22T00:00:00-05:00</published><updated>2017-03-22T00:00:00-05:00</updated><id>http://localhost:4000/2017/03/22/ambient-occlusion-in-metal</id><content type="html" xml:base="http://localhost:4000/2017/03/22/ambient-occlusion-in-metal.html">Today we will be looking into __ambient occlusion__. We are going to work on the playground we used in [Shadows in Metal part 2](http://metalkit.org/2017/02/28/shadows-in-metal-part-2.html) and build up on that. First, letâ€™s add a new object type - a rectangular box:

{% highlight swift %}struct Box {
    float3 center;
    float size;
    Box(float3 c, float s) {
        center = c;
        size = s;
    }
};
{% endhighlight %}

Next, letâ€™s also add a new distance function for our new struct:

{% highlight swift %}float distToBox(Ray r, Box b) {
    float3 d = abs(r.origin - b.center) - float3(b.size);
    return min(max(d.x, max(d.y, d.z)), 0.0) + length(max(d, 0.0));
}
{% endhighlight %}

Then, update our scene to something new: 

{% highlight swift %}float distToScene(Ray r) {
    Plane p = Plane(0.0);
    float d2p = distToPlane(r, p);
    Sphere s1 = Sphere(float3(0.0, 0.5, 0.0), 8.0);
    Sphere s2 = Sphere(float3(0.0, 0.5, 0.0), 6.0);
    Sphere s3 = Sphere(float3(10., -5., -10.), 15.0);
    Box b = Box(float3(1., 1., -4.), 1.);
    float dtb = distToBox(r, b);
    float d2s1 = distToSphere(r, s1);
    float d2s2 = distToSphere(r, s2);
    float d2s3 = distToSphere(r, s3);
    float dist = differenceOp(d2s1, d2s2);
    dist = differenceOp(dist, d2s3);
    dist = unionOp(dist, dtb);
    dist = unionOp(d2p, dist);
    return dist;
}
{% endhighlight %}

What we did here was to first draw a sphere with a radius of `8`, one with a radius of `6` and take the difference between them. Since they have the same center the smaller one would not be visible unless we made a cross sectioning somehow. That was exactly why we used a third sphere, much larger and with a different center. We took the difference again and we could now see the result of the first difference. Finally, we added a box in there for a nicer, more diverse view. If you run the playground now, you should see something similar: 

![alt text](https://github.com/MetalKit/images/raw/master/ao_1.png &quot;1&quot;)

Next, letâ€™s delete the __lighting()__ and __shadow()__ functions as we donâ€™t need them anymore. Also, delete the __Light__ struct and its two instances inside the kernel. Now let's create an `ambient occlusion` surrogate function:

{% highlight swift %}float ao(float3 pos, float3 n) {
    return n.y * 0.5 + 0.5;
}
{% endhighlight %}

Weâ€™re just using the normalâ€™s `y` component for light, which is like having a light directly above. Inside the kernel, right after creating the normal (inside the `else` block), call the `ao()` function:

{% highlight swift %}float o = ao(ray.origin, n);
col = col * o;
{% endhighlight %}

There are no shadows anymore, only a basic (directly above) light. If you run the playground now, you should see something similar:

![alt text](https://github.com/MetalKit/images/raw/master/ao_2.png &quot;2&quot;)

Time to get some real `ambient occlusion` now. _Ambient_ means the light does not come from a well defined light source but rather means general background lighting. _Occlusion_ means how much ambient light is blocked. We take the point on the surface where our ray hits and look at whatâ€™s around it. If thereâ€™s an object anywhere around it, that will block most of the light in the scene, so this is a dark area. If thereâ€™s nothing around it, then the area is well lit. For in between situations though, we need to figure out more precisely how much light was occluded. Introducing the __cone tracing__ concept.

The idea of `cone tracing` is using a cone in the scene, instead of a ray. If the cone intersects an object, we donâ€™t just have a simple `true/false` result. We can find out how much of the cone the object covers at that point. But how do we even trace a cone? We could make a cone using many spheres. Try to imagine several spheres along a line, very small at one end, big at the other end. This is as good a cone approximation we can get here. Here are the steps we want to take:

- Start at the point on the surface
- March out from the surface, along the normal
- For each iteration, determine how much of the sphere is filled by the scene using distance function
- For each iteration, double the distance from the surface, and also double the size of the sphere

Since we are doubling the sphere size at each step, that means we travel out from the surface very fast so we need fewer iterations. That also gives us a nice wide cone. Here is the complete `ao()` function:

{% highlight swift %}float ao(float3 pos, float3 n) {
    float eps = 0.01;
    pos += n * eps * 2.0;
    float occlusion = 0.0;
    for (float i=1.0; i&lt;10.0; i++) {
        float d = distToScene(Ray(pos, float3(0)));
        float coneWidth = 2.0 * eps;
        float occlusionAmount = max(coneWidth - d, 0.);
        float occlusionFactor = occlusionAmount / coneWidth;
        occlusionFactor *= 1.0 - (i / 10.0);
        occlusion = max(occlusion, occlusionFactor);
        eps *= 2.0;
        pos += n * eps;
    }
    return max(0.0, 1.0 - occlusion);
}
{% endhighlight %}

Let's go over the code, line by line. First we define the __eps__ variable which is both the cone radius and the distance from the surface. Then, we move away a bit to prevent hitting surface we're moving away from. Next, we define the __occlusion__ variable which is initially nil (scene is all lit). Then, we enter the loop and at each iteration we get the scene distance, double the radius so we know how much of the cone is occluded, make sure we eliminate negative values for the light, get the amount (ratio) of occlusion scaled by the cone width, set a lower impact for more distant occluders (the iteration count gives us this), preserve the highest occlusion value so far, double the __eps__ value and finally move along the normal by that distance. We then return a value that represents how much light reaches this point.  

Now lets have a __camera__ struct. It needs a position. Instead of camera direction we'll just store a __ray__. Finally the __rayDivergence__ gives us a factor of how much the ray spreads.

{% highlight swift %}struct Camera {
    float3 position;
    Ray ray = Ray(float3(0), float3(0));
    float rayDivergence;
    Camera(float3 pos, Ray r, float div) {
        position = pos;
        ray = r;
        rayDivergence = div;
    }
};
{% endhighlight %}

Next, we need to set up the camera. It needs the camera position, a look-at target, the field of view and the view coordinates:

{% highlight swift %}Camera setupCam(float3 pos, float3 target, float fov, float2 uv, int x) {
    uv *= fov;
    float3 cw = normalize(target - pos );
    float3 cp = float3(0.0, 1.0, 0.0);
    float3 cu = normalize(cross(cw, cp));
    float3 cv = normalize(cross(cu, cw));
    Ray ray = Ray(pos, normalize(uv.x * cu + uv.y * cv + 0.5 * cw));
    Camera cam = Camera(pos, ray, fov / float(x));
    return cam;
}
{% endhighlight %}

Now we just need to initialize the camera. We'll have it circling the scene, looking at the center __(0,0,0)__. Add this to the kernel, just after you set up the `uv` variable:
 
{% highlight swift %}float3 camPos = float3(sin(time) * 10., 3., cos(time) * 10.);
Camera cam = setupCam(camPos, float3(0), 1.25, uv, width);
{% endhighlight %}
 
Then delete the __ray__ variable, and replace everywhere it was used in the kernel with __cam.ray__ instead. If you run the playground now, you should see something similar:

![alt text](https://github.com/MetalKit/images/raw/master/ao_3.png &quot;3&quot;)

To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/4ltSWf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual. I want to thanks [Chris](https://twitter.com/_psonice) again for his assistance.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/gpu3d&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Today we will be looking into ambient occlusion. We are going to work on the playground we used in Shadows in Metal part 2 and build up on that. First, letâ€™s add a new object type - a rectangular box:</summary></entry><entry><title type="html">Shadows in Metal part 2</title><link href="http://localhost:4000/2017/02/28/shadows-in-metal-part-2.html" rel="alternate" type="text/html" title="Shadows in Metal part 2" /><published>2017-02-28T00:00:00-06:00</published><updated>2017-02-28T00:00:00-06:00</updated><id>http://localhost:4000/2017/02/28/shadows-in-metal-part-2</id><content type="html" xml:base="http://localhost:4000/2017/02/28/shadows-in-metal-part-2.html">In this second part of the series, we will be looking into __soft shadows__. We are going to work on the playground we used in [Raymarching in Metal](http://metalkit.org/2016/12/30/raymarching-in-metal.html) and build up on that because it was already set up for `3D` objects. Letâ€™s set up a basic scene that has a sphere, a plane, a light and a ray: 

{% highlight swift %}struct Ray {
    float3 origin;
    float3 direction;
    Ray(float3 o, float3 d) {
        origin = o;
        direction = d;
    }
};

struct Sphere {
    float3 center;
    float radius;
    Sphere(float3 c, float r) {
        center = c;
        radius = r;
    }
};

struct Plane {
    float yCoord;
    Plane(float y) {
        yCoord = y;
    }
};

struct Light {
    float3 position;
    Light(float3 pos) {
        position = pos;
    }
};
{% endhighlight %}

Next, we create a few `distance operation` functions that help us determine distances between elements of the scene: 

{% highlight swift %}float unionOp(float d0, float d1) {
    return min(d0, d1);
}

float differenceOp(float d0, float d1) {
    return max(d0, -d1);
}

float distToSphere(Ray ray, Sphere s) {
    return length(ray.origin - s.center) - s.radius;
}

float distToPlane(Ray ray, Plane plane) {
    return ray.origin.y - plane.yCoord;
}
{% endhighlight %}

Next, we create a __distanceToScene()__ function which gives us the closest distance to any object in the scene. We use these functions to generate a shape that looks like a hollow sphere with holes:

{% highlight swift %}float distToScene(Ray r) {
    Plane p = Plane(0.0);
    float d2p = distToPlane(r, p);
    Sphere s1 = Sphere(float3(2.0), 1.9);
    Sphere s2 = Sphere(float3(0.0, 4.0, 0.0), 4.0);
    Sphere s3 = Sphere(float3(0.0, 4.0, 0.0), 3.9);
    Ray repeatRay = r;
    repeatRay.origin = fract(r.origin / 4.0) * 4.0;
    float d2s1 = distToSphere(repeatRay, s1);
    float d2s2 = distToSphere(r, s2);
    float d2s3 = distToSphere(r, s3);
    float dist = differenceOp(d2s2, d2s3);
    dist = differenceOp(dist, d2s1);
    dist = unionOp(d2p, dist);
    return dist;
}
{% endhighlight %}

Everything we wrote so far is old code, just refactored from the _Raymarching_ article. Let's talk about __normals__ and why they are needed. If we have a flat floor - like our plane - the normal is always `(0, 1, 0)`, that is, pointing up. This case is trivial though. The normal in `3D` space is a `float3` and we need to know its position on the ray. Assume the ray just touches the left side of the sphere. The normal should be `(-1, 0, 0)`, that is, pointing to the left and away from the sphere. If the ray moves slightly to the right of that point, itâ€™s inside the sphere `(eg. -0.001)`. If the ray moves slightly to the left, itâ€™s outside the sphere `(eg. 0.001)`. If we subtract left from right we get `-0.001 - 0.001 = -0.002` which points to the left, so this is our `x` coordinate of the normal. We then repeat this for `y` and `z`. We use a `2D` vector named __eps__ so we can easily do [vector swizzling](https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)) using the chosen value `0.001` for various coordinates as needed in each case: 

{% highlight swift %}float3 getNormal(Ray ray) {
    float2 eps = float2(0.001, 0.0);
    float3 n = float3(distToScene(Ray(ray.origin + eps.xyy, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.xyy, ray.direction)),
                      distToScene(Ray(ray.origin + eps.yxy, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.yxy, ray.direction)),
                      distToScene(Ray(ray.origin + eps.yyx, ray.direction)) -
                      distToScene(Ray(ray.origin - eps.yyx, ray.direction)));
    return normalize(n);
}
{% endhighlight %}

Finally, we are ready to see some visuals. We again use the old `Raymarching` code and at the end of the kernel function we just add the normal so we can interpolate it with the color for every pixel:

{% highlight swift %}kernel void compute(texture2d&lt;float, access::write&gt; output [[texture(0)]],
                    constant float &amp;time [[buffer(0)]],
                    uint2 gid [[thread_position_in_grid]]) {
    int width = output.get_width();
    int height = output.get_height();
    float2 uv = float2(gid) / float2(width, height);
    uv = uv * 2.0 - 1.0;
    uv.y = -uv.y;
    Ray ray = Ray(float3(0., 4., -12), normalize(float3(uv, 1.)));
    float3 col = float3(0.0);
    for (int i=0; i&lt;100; i++) {
        float dist = distToScene(ray);
        if (dist &lt; 0.001) {
            col = float3(1.0);
            break;
        }
        ray.origin += ray.direction * dist;
    }
    float3 n = getNormal(ray);
    output.write(float4(col * n, 1.0), gid);
}
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_4.png &quot;4&quot;)

Now that we have normals, we can calculate lighting for each pixel in the scene, using the __lighting()__ function. First we need to know the direction to the light (`lightRay`) which we get by normalizing the light position and the current ray. For __diffuse__ lighting we need the angle between the normal and the `lightRay`, that is, the dot product of the two. For __specular__ lighting we need reflections on surfaces, and they depend on the angle weâ€™re looking at. The difference is in this case we first cast a ray into the scene, reflect it from the surface and then we measure the angle between the reflected ray and the `lightRay`. We then take a high power of that value to make it much sharper. Finally we return the combined light:

{% highlight swift %}float lighting(Ray ray, float3 normal, Light light) {
    float3 lightRay = normalize(light.position - ray.origin);
    float diffuse = max(0.0, dot(normal, lightRay));
    float3 reflectedRay = reflect(ray.direction, normal);
    float specular = max(0.0, dot(reflectedRay, lightRay));
    specular = pow(specular, 200.0);
    return diffuse + specular;
}
{% endhighlight %}

Replace the last line in the kernel function with these lines:

{% highlight swift %}Light light = Light(float3(sin(time) * 10.0, 5.0, cos(time) * 10.0));
float l = lighting(ray, n, light);
output.write(float4(col * l, 1.0), gid);
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_5.png &quot;5&quot;)

Next, shadows! We pretty much use the __shadow()__ function from the first part of this series, with few modifications. We normalize the direction of the light (`lightDir`) and then we just keep updating `distAlongRay` as we march along the ray:

{% highlight swift %}float shadow(Ray ray, Light light) {
    float3 lightDir = light.position - ray.origin;
    float lightDist = length(lightDir);
    lightDir = normalize(lightDir);
    float distAlongRay = 0.01;
    for (int i=0; i&lt;100; i++) {
        Ray lightRay = Ray(ray.origin + lightDir * distAlongRay, lightDir);
        float dist = distToScene(lightRay);
        if (dist &lt; 0.001) {
            return 0.0;
            break;
        }
        distAlongRay += dist;
        if (distAlongRay &gt; lightDist) { break; }
    }
    return 1.0;
}
{% endhighlight %}

Replace the last line in the kernel function with these lines:

{% highlight swift %}float s = shadow(ray, light);
output.write(float4(col * l * s, 1.0), gid);
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_6.png &quot;6&quot;)

Let's get some `soft shadows` in the scene. In real life, a shadow spreads out the farther it gets from an object. For example, if there is a cube on the floor, at a cube's vertex we get a sharp shadow but farther away from the cube it looks more like a blurred shadow. In other words, we start at some point on the floor, we march towards the light and either hit or miss. Hard shadows are straightforward: we hit something, it's in the shadow. Soft shadows have in-between stages. Update the __shadow()__ function with these lines:

{% highlight swift %}float shadow(Ray ray, float k, Light l) {
    float3 lightDir = l.position - ray.origin;
    float lightDist = length(lightDir);
    lightDir = normalize(lightDir);
    float eps = 0.1;
    float distAlongRay = eps * 2.0;
    float light = 1.0;
    for (int i=0; i&lt;100; i++) {
        Ray lightRay = Ray(ray.origin + lightDir * distAlongRay, lightDir);
        float dist = distToScene(lightRay);
        light = min(light, 1.0 - (eps - dist) / eps);
        distAlongRay += dist * 0.5;
        eps += dist * k;
        if (distAlongRay &gt; lightDist) { break; }
    }
    return max(light, 0.0);
}
{% endhighlight %}

You will notice that we are starting with a white (`1.0`) light this time and we use an attenuator (__k__) to get various (intermediate) values of light. The __eps__ variable tells us how much wider the beam is as we go out into the scene. A thin beam means sharp shadow while a wide beam means soft shadow. We start with a small `distAlongRay` because otherwise the surface at this point would shadow itself. We then travel along the ray as we did for the hard shadows, then we get the distance to the scene, after that we subtract `dist` from `eps` (the beam width) and divide it by `eps`. This gives us the percentage of beam covered. If we invert it (`1 - beam width`) we get the percentage of beam that is in the light. We take the minimum of this new value and `light` to preserve the darkest shadow as we march along the ray. We then again move along the ray and increase the beam width in proportion to the distance traveled and scaled by `k`. If we're past the light, we break out of the loop. Finally, we want to avoid negative values for the light so we return the maximum between __0.0__ and the value of light. Now let's adapt the kernel code to work with the new `shadow()` function:

{% highlight swift %}float3 col = float3(1.0);
bool hit = false;
for (int i=0; i&lt;200; i++) {
    float dist = distToScene(ray);
    if (dist &lt; 0.001) {
        hit = true;
        break;
    }
    ray.origin += ray.direction * dist;
}
if (!hit) {
    col = float3(0.5);
} else {
    float3 n = getNormal(ray);
    Light light = Light(float3(sin(time) * 10.0, 5.0, cos(time) * 10.0));
    float l = lighting(ray, n, light);
    float s = shadow(ray, 0.3, light);
    col = col * l * s;
}
Light light2 = Light(float3(0.0, 5.0, -15.0));
float3 lightRay = normalize(light2.position - ray.origin);
float fl = max(0.0, dot(getNormal(ray), lightRay) / 2.0);
col = col + fl;
output.write(float4(col, 1.0), gid);
{% endhighlight %}

Notice we switched to having a rather white color by default. Then we added a boolean named __hit__ that tells us if we hit the object or not. We determine we have a hit if the distance to scene is within __0.001__. If we didn't hit anything, just color everything in grey, otherwise determine the shadow value. At the end we just add another (fixed) light source in front of the scene so see the shadows in greater detail. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_7.png &quot;7&quot;)

To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/XltSWf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">In this second part of the series, we will be looking into soft shadows. We are going to work on the playground we used in Raymarching in Metal and build up on that because it was already set up for 3D objects. Letâ€™s set up a basic scene that has a sphere, a plane, a light and a ray:</summary></entry><entry><title type="html">Shadows in Metal part 1</title><link href="http://localhost:4000/2017/01/31/shadows-in-metal-part-1.html" rel="alternate" type="text/html" title="Shadows in Metal part 1" /><published>2017-01-31T00:00:00-06:00</published><updated>2017-01-31T00:00:00-06:00</updated><id>http://localhost:4000/2017/01/31/shadows-in-metal-part-1</id><content type="html" xml:base="http://localhost:4000/2017/01/31/shadows-in-metal-part-1.html">A quite important topic in `Computer Graphics` is _lighting and shadows_. This will be a first episode from a multi-part series about __Shadows__ in `Metal`. We are going to work on the playground we used in [Using metal part 15](http://metalkit.org/2016/06/23/using-metalkit-part-15.html) and build up on that. Letâ€™s set up a basic scene: 

{% highlight swift %}float differenceOp(float d0, float d1) {
    return max(d0, -d1);
}

float distanceToRect( float2 point, float2 center, float2 size ) {
    point -= center;
    point = abs(point);
    point -= size / 2.;
    return max(point.x, point.y);
}

float distanceToScene( float2 point ) {
    float d2r1 = distanceToRect( point, float2(0.), float2(0.45, 0.85) );
    float2 mod = point - 0.1 * floor(point / 0.1);
    float d2r2 = distanceToRect( mod, float2( 0.05 ), float2(0.02, 0.04) );
    float diff = differenceOp(d2r1, d2r2);
    return diff;
}
{% endhighlight %}

We first created the __differenceOp()__ function which returns the difference between two signed distances. This comes in handy when we want to _carve_ shapes out of other shapes. Next, we created the __distanceToRect()__ function which determines if a given point is either inside or outside a rectangle. On the `1st` line we offset the current coordinates by the given center. On the `2nd` line we get the symmetrical coordinates of the given point. On the `3rd` line we get the distance to any edge. Then, we created the __distanceToScene()__ function which gives us the closest distance to any object in the scene. Note that the `fmod()` function in `MSL` uses `trunc()` instead of `floor()` so we need to create a custom __mod__ operator here because we also want to use the negative values, so we use the `GLSL` specification for `mod()` which is `x - y * floor(x/y)`. We need the `modulus` operator to draw many small rectangles mirrored on a distance of __0.1__ from each other. Finally, we use these functions to generate a shape that looks a bit like a tall building with windows:

{% highlight swift %}kernel void compute(texture2d&lt;float, access::write&gt; output [[texture(0)]],
                    constant float &amp;timer [[buffer(0)]],
                    uint2 gid [[thread_position_in_grid]])
{
    int width = output.get_width();
    int height = output.get_height();
    float2 uv = float2(gid) / float2(width, height);
    uv = uv * 2.0 - 1.0;
    float d2scene = distanceToScene(uv);
    bool i = d2scene &lt; 0.0;
    float4 color = i ? float4( .1, .5, .5, 1. ) : float4( .7, .8, .8, 1. );
    output.write(color, gid);
}
{% endhighlight %}

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_1.png &quot;1&quot;)

For shadows to work we need to first - get the distance to the light, second - get the direction to the light, and third - step in that direction until we either reach the light or hit an object. So let's create a light at position __lightPos__ which we will animate for fun. We use that good old __timer__ uniform that we have it handy passed from the host (`API`) code. Then, we get the distance from any given point to `lightPos` and then just color the pixel based on the distance from the light - if not inside an object. We want the color to be lighter closer to the light and darker when further away. We use the `max()` function to avoid negative values for the brightness of the light. Replace the last line in the kernel with the lines below:
  
{% highlight swift %}float2 lightPos = float2(1.3 * sin(timer), 1.3 * cos(timer));
float dist2light = length(lightPos - uv);
color *= max(0.0, 2. - dist2light );
output.write(color, gid);
{% endhighlight %}  

If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_2.png &quot;2&quot;)

We did the first two steps (light position and direction) so let's proceed to doing the third one - the actual shadow function:

{% highlight swift %}float getShadow(float2 point, float2 lightPos) {
    float2 lightDir = lightPos - point;
    float dist2light = length(lightDir);
    for (float i=0.; i &lt; 300.; i++) {
        float distAlongRay = dist2light * (i / 300.);
        float2 currentPoint = point + lightDir * distAlongRay;
        float d2scene = distanceToScene(currentPoint);
        if (d2scene &lt;= 0.) { return 0.; }
    }
    return 1.;
} 
{% endhighlight %}

Let's go over the code, line by line. We first get the direction from the point to the light. Next, we find the distance to the light so we know how far we need to move along this light ray. Then, we use a loop to divide the ray into many smaller steps. If we don't use enough steps, we might jump past our object and that would leave &quot;holes&quot; in the shadow. Next, we calculate how far along the ray we are currently and move along the ray by this distance to find the point in space we're sampling at. Then, we see how far we are from the surface at that point and then test if we are inside an object. If we are, return __0__ because we are in the shadow, otherwise return __1__ as the ray did not hit any object. It is finally time to see some shadows! In the kernel, replace the last line with the lines below:

{% highlight swift %}float shadow = getShadow(uv, lightPos);
shadow = shadow * 0.5 + 0.5;
color *= shadow;
output.write(color, gid);
{% endhighlight %}

We use the value __0.5__ to attenuate the effect of the shadow, however, feel free to play with various values and notice how it affects itc. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/shadows_3.png &quot;3&quot;)

Right now the loop goes in one-pixel steps which is not good performance-wise. We can improve that a little by accelerating the steps along the ray. We don't need to move in really small steps. We can move in big steps so long as we don't step past our object. We can safely step in _any_ direction by the distance to the scene instead of a fixed step size, and this way we skip over empty areas really fast! When finding the distance to the nearest surface, we don't know what direction the surface is in so in fact we have the _radius_ of a circle that intersects with the nearest part of the scene. We can trace along the ray, always stepping to the edge of the circle, until the circle radius becomes __0__ which means it intersected a surface. Oh, right, this is the __raymarching__ technique we learned about last time! Simply replace the content of the __getShadow()__ function with the lines below:

{% highlight swift %}float2 lightDir = normalize(lightPos - point);
float dist2light = length(lightDir);
float distAlongRay = 0.0;
for (float i=0.0; i &lt; 80.; i++) {
    float2 currentPoint = point + lightDir * distAlongRay;
    float d2scene = distanceToScene(currentPoint);
    if (d2scene &lt;= 0.001) { return 0.0; }
    distAlongRay += d2scene;
    if (distAlongRay &gt; dist2light) { break; }
}
return 1.;
{% endhighlight %}
 
In `raymarching` the size of the step depends on the distance from the surface. In empty areas it jumps big distances and it can travel a long way. But if itâ€™s parallel to the object and close to it, the distance is always small so the jump size is also small. That means the ray travels very slowly. With a fixed number of steps, it doesnâ€™t travel far. With __80__ or more steps we should be safe from getting &quot;holes&quot; in the shadow. If you run the playground again the output looks similar except the shadow is faster now. To see an animated version of this code, use the `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/lt3SzB&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;

This type of shadows is called `hard shadows`. Next time we will be looking into `soft shadows` which are more realistic and better looking. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">A quite important topic in Computer Graphics is lighting and shadows. This will be a first episode from a multi-part series about Shadows in Metal. We are going to work on the playground we used in Using metal part 15 and build up on that. Letâ€™s set up a basic scene:</summary></entry><entry><title type="html">Raymarching in Metal</title><link href="http://localhost:4000/2016/12/30/raymarching-in-metal.html" rel="alternate" type="text/html" title="Raymarching in Metal" /><published>2016-12-30T00:00:00-06:00</published><updated>2016-12-30T00:00:00-06:00</updated><id>http://localhost:4000/2016/12/30/raymarching-in-metal</id><content type="html" xml:base="http://localhost:4000/2016/12/30/raymarching-in-metal.html">__Raymarching__ is a fast rendering method used in realtime graphics. The geometry is usually not passed to the renderer but rather created in the shader using __Signed Distance Fields (SDF)__ functions that describe the shortest distance between a point and the surface of any object in the scene. The `SDF` returns a negative number if the point is inside of an object. Also, `SDFs` are useful because they allow us to reduce the number of samples used by `Ray Tracing`.  Similar to _Ray Tracing_, in `Raymarching` we also have a ray cast for each pixel on the view plane and each ray is used to determine if there is an intersection with an object. 

The difference between the two techniques is that in _Ray Tracing_ the intersection is determined by a strict set of equations while in `Raymarching` the intersection is approximated. Using `SDFs` we can _march_ along the ray until we get close enough to an object. This is inexpensive to compute compared to exactly determining intersections which could become very expensive when there are many objects in the scene and the lighting is complex. Another great use case for `Raymarching` is volumetric rendering (fog, water, clouds) which _Ray Tracing_ cannot easily do because determining intersections with such volumes is quite difficult.

To follow allong, you can use the playground from [Using MetalKit part 10](http://metalkit.org/2016/05/02/using-metalkit-part-10.html), slightly modified as explained next. Letâ€™s start with two basic building blocks we need at the very minimum in our kernel: a ray and an object (sphere).

{% highlight swift %}struct Ray {
    float3 origin;
    float3 direction;
    Ray(float3 o, float3 d) {
        origin = o;
        direction = d;
    }
};

struct Sphere {
    float3 center;
    float radius;
    Sphere(float3 c, float r) {
        center = c;
        radius = r;
    }
};
{% endhighlight %}

As we did back in _part 10_, let's also write a `SDF` for calculating the distance from a given point to the sphere. The difference from the old function is that now our point is _marching_ along the ray, so we use the ray position instead:

{% highlight swift %}float distToSphere(Ray ray, Sphere s) {
    return length(ray.origin - s.center) - s.radius;
}
{% endhighlight %}

All we had to do back then was to calculate the distance from any given point to a circle (not a sphere because we did not have `3D` back then) like this:

{% highlight swift %}float dist(float2 point, float2 center, float radius) {
    return length(point - center) - radius;
}

...
float distToCircle = dist(uv, float2(0.), 0.5);
bool inside = distToCircle &lt; 0.;
output.write(inside ? float4(1.) : float4(0.), gid);
...
{% endhighlight %}

We now need to have a ray and march along with it through the scene, so replace those last three lines in the kernel with the following lines:

{% highlight swift %}Sphere s = Sphere(float3(0.), 1.);
Ray ray = Ray(float3(0., 0., -3.), normalize(float3(uv, 1.0)));
float3 col = float3(0.);
for (int i=0.; i&lt;100.; i++) {
    float dist = distToSphere(ray, s);
    if (dist &lt; 0.001) {
        col = float3(1.);
        break;
    }
    ray.origin += ray.direction * dist;
}
output.write(float4(col, 1.), gid);
{% endhighlight %}

Let's go over the code line by line. We first create a sphere object and a ray. Notice that as ray's `z` value approaches `0`, the sphere seems bigger because the ray is closer to the scene, and vice versa, when it goes away from `0`, the sphere seems smaller for the obvious reason -- we use our ray as our implicit `camera`. Next we define the color to be initially a solid black. Now comes the very essence of `raymarching`! We loop for a given number of times (steps) to make sure we get enough precision. We go with `100` in this case but you can try with a bigger number of steps and see how the quality of the rendered image improves, at the expense of more computing resources used, however. Inside the loop we calculate the distance from our current position along the ray to the scene, while also checking if we reached an object in the scene, and if we did, we color it in solid white and break out of this particular iteration, or otherwise update the ray position by moving it closer to the scene. 

Notice that we normalized the ray direction to cover edge cases where for example the length of the vector `(1, 1, 1)` (corner of the screen) would have a value of `sqrt(1 * 1 + 1 * 1 + 1 * 1)` which approximates to `1.73`. That means we would need to move the ray position forward by `1.73 * dist` which is almost double the distance we need to move forward, thus making us miss the object by overshooting the ray beyond the intersection point. For that reason, we normalize the direction, to make sure its length will always be `1`. Finally, we write the color to the output texture. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/raymarching1.png &quot;1&quot;)

Now let's create a function named __distToScene__ that only takes a ray in as argument because all we care now is to find the shortest distance to a complex scene that contains multiple objects. Next, we move the code related to the sphere inside this new function where we return only the distance to the sphere (for now). Then, we change the sphere position to `(1, 1, 1)` and its radius to `0.5` which means the sphere is now in the `0.5 ... 1.5` range. Here comes a neat trick to do instancing: if we repeat the space between `0.0 ... 2.0`, the sphere is safely inside. Next, we make a local copy of the ray and modulus its origin. Then we use the repeating ray with the `distToSphere()` function. 

{% highlight swift %}float distToScene(Ray r) {
    Sphere s = Sphere(float3(1.), 0.5);
    Ray repeatRay = r;
    repeatRay.origin = fmod(r.origin, 2.0);
    return distToSphere(repeatRay, s);
}
{% endhighlight %}

By using the `fmod` function we repeated the space throughout the entire screen and pratically created an infinite number of spheres, each with its own (repeated) ray. Of course, we will only see the ones bounded by the `x` and `y` coordinates of the screen, however, the `z` coordinate will let us see how the spheres go indefinitely in depth. Inside the kernel, remove the sphere line, move the ray to a really far location, modify `dist` to rather give us the distance to the scene, and finally change the last line to give us some nice colors:

{% highlight swift %}Ray ray = Ray(float3(1000.), normalize(float3(uv, 1.0)));
...
float dist = distToScene(ray);
...
output.write(float4(col * abs((ray.origin - 1000.) / 10.0), 1.), gid);
{% endhighlight %}

We are multiplying the color by the ray position. We divide by `10.0` because the scene is quite big and the ray position is bigger than `1.0` in most places, which would give us a solid white. We use `abs()` because on the left side of the screen `x` is lower than `0` which would give us a solid black so we basically mirror the top/bottom and left/right colors. Finally, we offset the ray position by `1000` to match the ray origin (camera) we set. If you run the playground now you should see a similar image:

![alt text](https://github.com/MetalKit/images/raw/master/raymarching2.png &quot;2&quot;)

Next, let's animate the scene! We have seen in [part 12](http://metalkit.org/2016/05/18/using-metalkit-part-12.html) how to send useful _uniforms_ to the `GPU`, such as the `time` so we are not going to discuss about how to implement that again here.

{% highlight swift %}float3 camPos = float3(1000. + sin(time) + 1., 1000. + cos(time) + 1., time);
Ray ray = Ray(camPos, normalize(float3(uv, 1.)));
...
float3 posRelativeToCamera = ray.origin - camPos;
output.write(float4(col * abs((posRelativeToCamera) / 10.0), 1.), gid);
{% endhighlight %}

We added `time` to all three coordinates, but we only fluctuate the `x` and `y` while keeping `z` a straight line. The `1.` part is there just to stop the camera crashing into the nearest sphere. To see an animated version of this code, I used a `Shadertoy` embedded player below. Just hover over it and click the play button to watch it in action:

&lt;iframe width=&quot;740&quot; height=&quot;450&quot; frameborder=&quot;0&quot; src=&quot;https://www.shadertoy.com/embed/XtcSDf&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br /&gt;
    
I want to thanks [Chris](https://twitter.com/_psonice) again for his assistance. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>by &lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Raymarching is a fast rendering method used in realtime graphics. The geometry is usually not passed to the renderer but rather created in the shader using Signed Distance Fields (SDF) functions that describe the shortest distance between a point and the surface of any object in the scene. The SDF returns a negative number if the point is inside of an object. Also, SDFs are useful because they allow us to reduce the number of samples used by Ray Tracing.  Similar to Ray Tracing, in Raymarching we also have a ray cast for each pixel on the view plane and each ray is used to determine if there is an intersection with an object.</summary></entry><entry><title type="html">Beginning Metal - a new course</title><link href="http://localhost:4000/2016/11/30/new-metal-course.html" rel="alternate" type="text/html" title="Beginning Metal - a new course" /><published>2016-11-30T00:00:00-06:00</published><updated>2016-11-30T00:00:00-06:00</updated><id>http://localhost:4000/2016/11/30/new-metal-course</id><content type="html" xml:base="http://localhost:4000/2016/11/30/new-metal-course.html">Our new website is completely revamped as you can see while navigating through the posts. The good news don't stop here. [Caroline](https://twitter.com/carolinebegbie), a good friend of mine and an awesome `Metal` programmer, just launched her new video course - [Beginning Metal](https://videos.raywenderlich.com/courses/beginning-metal/lessons/1) - through the `RayWenderlich.com` website. The first `2` lessons are free, however, to watch the remaining `13` videos you'd need to purchase membership for at least one month. Each of the lessons provide the sample code used in the videos as well as challenges that you would want to solve preferably before moving on to the next lesson. At the time of writing this post, there are only `2` more videos left to be released.

The course starts with the very basics of 3D graphics, learning what the GPU does and what the graphics pipeline is. The next couple of chapters teach you how to render in 2D - your first triangle. Then, you learn about the Metal Shading Language and the shader functions - why they run on the GPU, see how they fit into the pipeline, and how to position and color vertices. Next, youâ€™ll learn how to map textures to your geometry to make your graphics look even greater. The next couple of chapters take you through the transformation matrices to prepare you for the transition from `2D` to `3D`. Next, you'll learn about the `Model I/O` framework and how you can easily import models from modeling programs. The next couple of chapters teach you all about basic lighting using the Phong shading model. Another couple of chapters are dedicated to learning how to build a simple game using everything you've learned. The final chapter summarizes everything. 

I was absolutely impressed by the high quality of this course - quality which is actually the norm at `RayWenderlich.com` to be honest. The course teaches the total beginner as well as the more advanced Metal programmer to adopt the best practices for coding in Swift and Metal. The code builds up on previous chapters and in the end you have a minimal game engine that is fully functional and makes you crave for more Metal content in future courses. And I hope they do.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Our new website is completely revamped as you can see while navigating through the posts. The good news donâ€™t stop here. Caroline, a good friend of mine and an awesome Metal programmer, just launched her new video course - Beginning Metal - through the RayWenderlich.com website. The first 2 lessons are free, however, to watch the remaining 13 videos youâ€™d need to purchase membership for at least one month. Each of the lessons provide the sample code used in the videos as well as challenges that you would want to solve preferably before moving on to the next lesson. At the time of writing this post, there are only 2 more videos left to be released.

The course starts with the very basics of 3D graphics, learning what the GPU does and what the graphics pipeline is. The next couple of chapters teach you how to render in 2D - your first triangle. Then, you learn about the Metal Shading Language and the shader functions - why they run on the GPU, see how they fit into the pipeline, and how to position and color vertices. Next, youâ€™ll learn how to map textures to your geometry to make your graphics look even greater. The next couple of chapters take you through the transformation matrices to prepare you for the transition from 2D to 3D. Next, youâ€™ll learn about the Model I/O framework and how you can easily import models from modeling programs. The next couple of chapters teach you all about basic lighting using the Phong shading model. Another couple of chapters are dedicated to learning how to build a simple game using everything youâ€™ve learned. The final chapter summarizes everything.

I was absolutely impressed by the high quality of this course - quality which is actually the norm at RayWenderlich.com to be honest. The course teaches the total beginner as well as the more advanced Metal programmer to adopt the best practices for coding in Swift and Metal. The code builds up on previous chapters and in the end you have a minimal game engine that is fully functional and makes you crave for more Metal content in future courses. And I hope they do.

Until next time!</summary></entry><entry><title type="html">Using MetalKit part 2*3^2</title><link href="http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2.html" rel="alternate" type="text/html" title="Using MetalKit part 2*3^2" /><published>2016-10-01T00:00:00-05:00</published><updated>2016-10-01T00:00:00-05:00</updated><id>http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2</id><content type="html" xml:base="http://localhost:4000/2016/10/01/using-metalkit-part-2-3-2.html">Yes, as the title suggests, we're going to have another of those posts with math (and fun) in it. I was thinking the other day, what can we do while commuting for an hour or so, without internet and possibly without a laptop as well, just carrying an `iPad` with us. Luckily, the `iPad` now has the awesome `Swift Playgrounds` app.

Let's start with a new playground that runs a basic compute kernel. Since the current version of the `Swift Playgrounds` app does not yet let us edit the `Auxiliary Source Files`, where all our `Swift` and `Metal` files usually reside, we will have to write our code in the main playground page, but it is not that complicated. All we have to do is modify our `MetalView` initializer and let it take in an extra argument -- our shader/kernel code. Then we start building our code by adding more lines to this long string.

Let's start with a light blue sky background color:

{% highlight swift %}let shader =
&quot;#include &lt;metal_stdlib&gt;\n&quot; +
&quot;using namespace metal;&quot; +
&quot;kernel void k(texture2d&lt;float,access::write&gt; o[[texture(0)]],&quot; +
&quot;              uint2 gid[[thread_position_in_grid]]) {&quot; +
&quot;   float3 color = float3(0.5, 0.8, 1.0);&quot; +
&quot;   o.write(float4(color, 1.0), gid);&quot; +
&quot;}&quot;
{% endhighlight %}

If you run the playground now, the output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_1.png &quot;1&quot;)

Next, let's draw a gradient. we divide the current pixel coordinates to the screen dimensions and we get __UV__ -- a pair of floats between __(0-1)__. we then multiply the fixed color with __Y__ -- the vertical component of `UV` which gives us the gradient:

{% highlight swift %}&quot;   int width = o.get_width();&quot; +
&quot;   int height = o.get_height();&quot; +
&quot;   float2 uv = float2(gid) / float2(width, height);&quot; +
&quot;   color *= uv.y;&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_2.png &quot;2&quot;)

Let's work on a nicer background next. A smooth gradient would look like a great sunset. We can use __mix__ to blend colors. We tell the function to blend vertically, and take the complement of __Y__ to switch the colors:

{% highlight swift %}&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_3.png &quot;3&quot;)

From here we could go to drawing a black hole. We would achieve that by using a distance function (__length__) to draw black in the middle of the screen __(0.5, 0.5)__ and add more and more background color outside of it, until we reach the maximum value in the screen corners. Replace the last line with:

{% highlight swift %}&quot;   float2 q = uv - float2(0.5);&quot; +
&quot;   color *= length(q);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_4.png.png &quot;4&quot;)

Next we use __smootstep__ to draw a round shape that is black inside, blue outside and a blended color between __r__ and __(r + 0.01)__. Replace the last line with:

{% highlight swift %}&quot;   float r = 0.2;&quot; +
&quot;   color *= smoothstep(r, r + 0.01, length(q));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_5.png &quot;5&quot;)

If we're not satisfied with a circular perimeter, we could make it _bumpy_ by using math functions such as __cos__ and __atan2__. We generate here __9__ spikes (__frequency__) with a spike length (__amplitude__) of __0.1__:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_6.png &quot;6&quot;)

Adding the __X__ coordinate to the _cosine_ phase introduces a spike _bend-like_ effect:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_7.png &quot;7&quot;)

You can rotate them by adding a small number such as __1.0__ to the _cosine_ value:

{% highlight swift %}&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x + 1.0);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_8.png &quot;8&quot;)

If you think this is starting to look like a palm tree canopy, I see it too! We can draw its trunk using __abs__ which gives us horizontal/vertical distances instead of _euclidian_ distances (to a given point) like _length_ did, so let's take the __X__ distance and add these lines (we are reusing both __r__ and __color__) after the existing ones: 

{% highlight swift %}&quot;   r = 0.015;&quot; +
&quot;   color *= smoothstep(r, r + 0.002, abs(q.x));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_9.png &quot;9&quot;)

We can remove the unneeded part of the trunk by using another __smoothstep__ on the __Y__ coordinate:

{% highlight swift %}&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x))) * smoothstep(0.0, 0.1, q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_10.png &quot;10&quot;)

Since both the canopy and trunk are using __q__, modifying its value will move both:

{% highlight swift %}&quot;   float2 q = uv - float2(0.67, 0.29);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_11.png &quot;11&quot;)

By introducing a __sin__ function we can bend the trunk. A too small _frequency_ does not bend it enough while a too high _frequency_ bends it too much so __2.0__ seems right. An _amplitude_ of __0.25__ also moves the base of the trunk towards the edge of the screen so it looks right (as an aside, changing the sign from __+__ to __--__ will shift the base to the other side):

{% highlight swift %}&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x - 0.25 * sin(2.0 * q.y)))) * smoothstep(0.0, 0.1, q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_12.png &quot;12&quot;)

The trunk, however, is too smooth. To add irregularities to its surface we use __cos__ again. A high _frequency_ and low _amplitude_ seem to be what we need to make it look right:

{% highlight swift %}&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y);&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_13.png &quot;13&quot;)

Also, trunks are usually shaping the ground a little around their base, so an __exp__ function is what we need here because it grows slowly in the beginning and then it soars to the skies. We use an _attenuation_ factor of __-50.0__:

{% highlight swift %}&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y) + exp(-50.0 * (1.0 - uv.y));&quot; +
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_14.png &quot;14&quot;)

We can increase the presence of the second color by using __sqrt__ which gives us bigger numbers (when used on sub-unitary numbers) to work with. The sunset is about to end soon:

{% highlight swift %}&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +
{% endhighlight %}

The final image on the iPad should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_15.png &quot;15&quot;)

In conclusion, we saw how to use __sqrt__ to shape transitions, then __cos__ to create variations of ups and downs in shapes, then __exp__ that allows us to create curves, then __smoothstep__ for thresholding, then __abs__ for symmetry and __mix__ for blending. Still commuting? Why don't you take a look at how this nice clover was created:

![alt text](https://github.com/MetalKit/images/raw/master/chapter18_16.png &quot;16&quot;)

I want to say thanks to [Inigo Quilez](https://twitter.com/iquilezles) again, for keep inspiring me to write more and more about drawing with math. All the math in this tutorial belongs to him. The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Yes, as the title suggests, weâ€™re going to have another of those posts with math (and fun) in it. I was thinking the other day, what can we do while commuting for an hour or so, without internet and possibly without a laptop as well, just carrying an iPad with us. Luckily, the iPad now has the awesome Swift Playgrounds app.

Letâ€™s start with a new playground that runs a basic compute kernel. Since the current version of the Swift Playgrounds app does not yet let us edit the Auxiliary Source Files, where all our Swift and Metal files usually reside, we will have to write our code in the main playground page, but it is not that complicated. All we have to do is modify our MetalView initializer and let it take in an extra argument â€“ our shader/kernel code. Then we start building our code by adding more lines to this long string.

Letâ€™s start with a light blue sky background color:

let shader =
&quot;#include &amp;lt;metal_stdlib&amp;gt; &quot; +
&quot;using namespace metal;&quot; +
&quot;kernel void k(texture2d&amp;lt;float,access::write&amp;gt; o[[texture(0)]],&quot; +
&quot;              uint2 gid[[thread_position_in_grid]]) {&quot; +
&quot;   float3 color = float3(0.5, 0.8, 1.0);&quot; +
&quot;   o.write(float4(color, 1.0), gid);&quot; +
&quot;}&quot;

If you run the playground now, the output image should look like this:



Next, letâ€™s draw a gradient. we divide the current pixel coordinates to the screen dimensions and we get UV â€“ a pair of floats between (0-1). we then multiply the fixed color with Y â€“ the vertical component of UV which gives us the gradient:

&quot;   int width = o.get_width();&quot; +
&quot;   int height = o.get_height();&quot; +
&quot;   float2 uv = float2(gid) / float2(width, height);&quot; +
&quot;   color *= uv.y;&quot; +

The output image should look like this:



Letâ€™s work on a nicer background next. A smooth gradient would look like a great sunset. We can use mix to blend colors. We tell the function to blend vertically, and take the complement of Y to switch the colors:

&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +

The output image should look like this:



From here we could go to drawing a black hole. We would achieve that by using a distance function (length) to draw black in the middle of the screen (0.5, 0.5) and add more and more background color outside of it, until we reach the maximum value in the screen corners. Replace the last line with:

&quot;   float2 q = uv - float2(0.5);&quot; +
&quot;   color *= length(q);&quot; +

The output image should look like this:



Next we use smootstep to draw a round shape that is black inside, blue outside and a blended color between r and (r + 0.01). Replace the last line with:

&quot;   float r = 0.2;&quot; +
&quot;   color *= smoothstep(r, r + 0.01, length(q));&quot; +

The output image should look like this:



If weâ€™re not satisfied with a circular perimeter, we could make it bumpy by using math functions such as cos and atan2. We generate here 9 spikes (frequency) with a spike length (amplitude) of 0.1:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0);&quot; +

The output image should look like this:



Adding the X coordinate to the cosine phase introduces a spike bend-like effect:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x);&quot; +

The output image should look like this:



You can rotate them by adding a small number such as 1.0 to the cosine value:

&quot;   float r = 0.2 + 0.1 * cos(atan2(q.x, q.y) * 9.0 + 20.0 * q.x + 1.0);&quot; +

The output image should look like this:



If you think this is starting to look like a palm tree canopy, I see it too! We can draw its trunk using abs which gives us horizontal/vertical distances instead of euclidian distances (to a given point) like length did, so letâ€™s take the X distance and add these lines (we are reusing both r and color) after the existing ones:

&quot;   r = 0.015;&quot; +
&quot;   color *= smoothstep(r, r + 0.002, abs(q.x));&quot; +

The output image should look like this:



We can remove the unneeded part of the trunk by using another smoothstep on the Y coordinate:

&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x))) * smoothstep(0.0, 0.1, q.y);&quot; +

The output image should look like this:



Since both the canopy and trunk are using q, modifying its value will move both:

&quot;   float2 q = uv - float2(0.67, 0.29);&quot; +

The output image should look like this:



By introducing a sin function we can bend the trunk. A too small frequency does not bend it enough while a too high frequency bends it too much so 2.0 seems right. An amplitude of 0.25 also moves the base of the trunk towards the edge of the screen so it looks right (as an aside, changing the sign from + to â€“ will shift the base to the other side):

&quot;   color *= 1.0 - (1.0 - smoothstep(r, r + 0.002, abs(q.x - 0.25 * sin(2.0 * q.y)))) * smoothstep(0.0, 0.1, q.y);&quot; +

The output image should look like this:



The trunk, however, is too smooth. To add irregularities to its surface we use cos again. A high frequency and low amplitude seem to be what we need to make it look right:

&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y);&quot; +

The output image should look like this:



Also, trunks are usually shaping the ground a little around their base, so an exp function is what we need here because it grows slowly in the beginning and then it soars to the skies. We use an attenuation factor of -50.0:

&quot;   r = 0.015 + 0.002 * cos (120.0 * q.y) + exp(-50.0 * (1.0 - uv.y));&quot; +

The output image should look like this:



We can increase the presence of the second color by using sqrt which gives us bigger numbers (when used on sub-unitary numbers) to work with. The sunset is about to end soon:

&quot;   float3 color = mix(float3(1.0, 0.6, 0.1), float3(0.5, 0.8, 1.0), sqrt(1 - uv.y));&quot; +

The final image on the iPad should look like this:



In conclusion, we saw how to use sqrt to shape transitions, then cos to create variations of ups and downs in shapes, then exp that allows us to create curves, then smoothstep for thresholding, then abs for symmetry and mix for blending. Still commuting? Why donâ€™t you take a look at how this nice clover was created:



I want to say thanks to Inigo Quilez again, for keep inspiring me to write more and more about drawing with math. All the math in this tutorial belongs to him. The source code is posted on Github as usual.

Until next time!</summary></entry><entry><title type="html">Using MetalKit part 17</title><link href="http://localhost:4000/2016/09/24/using-metalkit-part-17.html" rel="alternate" type="text/html" title="Using MetalKit part 17" /><published>2016-09-24T00:00:00-05:00</published><updated>2016-09-24T00:00:00-05:00</updated><id>http://localhost:4000/2016/09/24/using-metalkit-part-17</id><content type="html" xml:base="http://localhost:4000/2016/09/24/using-metalkit-part-17.html">I am writing this article for three reasons: first, to tell you that I am working on updating all the `Metal` code to `Swift 3` and then moving the tutorials to a new home with a nicer design and a proper domain name; second, I wanted to show you a different way to work with `MetalKit` other than subclassing `MTKView`, that is, using the `MTKViewDelegate`; and third, I wanted to answer one of our readers' question about how to draw wireframes.

Let's start by using the code from `Part 4` which is an `Xcode` project but we will turn it into a playground this time. This is going to be a shockingly short tutorial but all you have to do is add the following line right before encoding the draw command:

{% highlight swift %}renderEncoder.setTriangleFillMode(.lines)
{% endhighlight %}

That's it! Run the playground and enjoy the wireframed triangle. If you don't want it to have an interpolated color, in the fragment shader also replace the return line with a constant color like green, for example:

{% highlight swift %}return half4(0.0, 1.0, 0.0, 1.0);
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter17.png &quot;2D&quot;)

For a `3D` rendering there is one more thing we need to do, disable the backface culling. If you're working in the playground from `Part 9` just comment out this line:

{% highlight swift %}commandEncoder.setCullMode(.back)
{% endhighlight %}

The output image should look like this:

![alt text](https://github.com/MetalKit/images/raw/master/chapter17_2.png &quot;3D&quot;)

The [source code](https://github.com/MetalKit/metal) is posted on `Github` as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">I am writing this article for three reasons: first, to tell you that I am working on updating all the Metal code to Swift 3 and then moving the tutorials to a new home with a nicer design and a proper domain name; second, I wanted to show you a different way to work with MetalKit other than subclassing MTKView, that is, using the MTKViewDelegate; and third, I wanted to answer one of our readersâ€™ question about how to draw wireframes.

Letâ€™s start by using the code from Part 4 which is an Xcode project but we will turn it into a playground this time. This is going to be a shockingly short tutorial but all you have to do is add the following line right before encoding the draw command:

renderEncoder.setTriangleFillMode(.lines)

Thatâ€™s it! Run the playground and enjoy the wireframed triangle. If you donâ€™t want it to have an interpolated color, in the fragment shader also replace the return line with a constant color like green, for example:

return half4(0.0, 1.0, 0.0, 1.0);

The output image should look like this:



For a 3D rendering there is one more thing we need to do, disable the backface culling. If youâ€™re working in the playground from Part 9 just comment out this line:

commandEncoder.setCullMode(.back)

The output image should look like this:



The source code is posted on Github as usual.

Until next time!</summary></entry><entry><title type="html">The Model I/O framework</title><link href="http://localhost:4000/2016/08/30/the-model-i-o-framework.html" rel="alternate" type="text/html" title="The Model I/O framework" /><published>2016-08-30T00:00:00-05:00</published><updated>2016-08-30T00:00:00-05:00</updated><id>http://localhost:4000/2016/08/30/the-model-i-o-framework</id><content type="html" xml:base="http://localhost:4000/2016/08/30/the-model-i-o-framework.html">__Model I/O__ was introduced in `2015` for `iOS 9` and `OS X 10.11` and it is a framework that helps us create more realistic and interactive graphics. We can use it to import/export `3D` assets, to describe lighting, materials and environments, to bake lights, to subdivide and voxelize meshes, and for physical based rendering. Model I/O easily integrates our assets with our code in various `3D APIs`:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_1.png &quot;1&quot;)

In order to import an asset we simply do:

{% highlight swift %}var url = URL(string: &quot;/Users/YourUsername/Desktop/imported.obj&quot;)
let asset = MDLAsset(url: url!)
{% endhighlight %}

To export an asset we do:

{% highlight swift %}url = URL(string: &quot;/Users/YourUsername/Desktop/exported.obj&quot;)
try! asset.export(to: url!)
{% endhighlight %}

Model I/O will save both the __.obj__ file and an additional __.mtl__ file that contains information about the object materials, such as in this example:

{% highlight text %}# Apple ModelI/O MTL File: exported.mtl

newmtl material_1
	Kd 0.8 0.8 0.8
	Ka 0 0 0
	Ks 0 0 0
	ao 0 0 0
	subsurface 0 0 0
	metallic 0 0 0
	specularTint 0 0 0
	roughness 0.9 0 0
	anisotropicRotation 0 0 0
	sheen 0.05 0 0
	sheenTint 0 0 0
	clearCoat 0 0 0
	clearCoatGloss 0 0 0
{% endhighlight %}

Integrating `Model I/O` with `Metal` takes four steps:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_2.png &quot;2&quot;)

### Step 1: set up the render pipeline state

First we create a vertex descriptor so we can pass input to the vertex function. The vertex descriptor is needed to describe the vertex attribute inputs to a render state pipeline. We need `3 x 4` bytes for the vertex position, `4 x 1` byte for color, `2 x 2` bytes for the texture coordinates and `4 x 1` byte for ambient occlusion. At the end we tell the descriptor how large (__24__) our `stride` is in total:

{% highlight swift %}let vertexDescriptor = MTLVertexDescriptor()
vertexDescriptor.attributes[0].offset = 0
vertexDescriptor.attributes[0].format = MTLVertexFormat.float3 // position
vertexDescriptor.attributes[1].offset = 12
vertexDescriptor.attributes[1].format = MTLVertexFormat.uChar4 // color
vertexDescriptor.attributes[2].offset = 16
vertexDescriptor.attributes[2].format = MTLVertexFormat.half2 // texture
vertexDescriptor.attributes[3].offset = 20
vertexDescriptor.attributes[3].format = MTLVertexFormat.float // occlusion
vertexDescriptor.layouts[0].stride = 24
let renderPipelineDescriptor = MTLRenderPipelineDescriptor()
renderPipelineDescriptor.vertexDescriptor = vertexDescriptor
let rps = device.newRenderPipelineStateWithDescriptor(renderPipelineDescriptor)
{% endhighlight %}

### Step 2: set up the asset initialization

We need to also create a `Model I/O` vertex descriptor to describe the layout of the vertex attributes in a mesh. We use a model named __Farmhouse.obj__ that also has a texture __Farmhouse.png__ (both already added to the sample project for you):

{% highlight swift %}let desc = MTKModelIOVertexDescriptorFromMetal(vertexDescriptor)
var attribute = desc.attributes[0] as! MDLVertexAttribute
attribute.name = MDLVertexAttributePosition
attribute = desc.attributes[1] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeColor
attribute = desc.attributes[2] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeTextureCoordinate
attribute = desc.attributes[3] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeOcclusionValue
let mtkBufferAllocator = MTKMeshBufferAllocator(device: device!)
let url = Bundle.main.url(forResource: &quot;Farmhouse&quot;, withExtension: &quot;obj&quot;)
let asset = MDLAsset(url: url!, vertexDescriptor: desc, bufferAllocator: mtkBufferAllocator)
{% endhighlight %}

Next, we load the texture for our asset:

{% highlight swift %}let loader = MTKTextureLoader(device: device)
let file = Bundle.main.path(forResource: &quot;Farmhouse&quot;, ofType: &quot;png&quot;)
let data = try Data(contentsOf: URL(fileURLWithPath: file))
let texture = try loader.newTexture(with: data, options: nil)
{% endhighlight %}

### Step 3: set up `MetalKit` mesh and submesh objects

We are now creating the meshes and submeshes needed in the final, fourth step. We also compute the __Ambient Occlusion__, which is a measure of geometry obstruction, and it tells us how much of the ambient light actually reaches any given pixel or point of our object, and and how much of this light is blocked by surrounding meshes. `Model I/O` provides a `UV` mapper that creates a `2D` texture and wraps it around the object's `3D` mesh. For every pixel in the texture we can compute the ambient occlusion value, which is just one extra float added for each vertex:

{% highlight swift %}let mesh = asset.object(at: 0) as? MDLMesh
mesh.generateAmbientOcclusionVertexColors(withQuality: 1, attenuationFactor: 0.98, objectsToConsider: [mesh], vertexAttributeNamed: MDLVertexAttributeOcclusionValue)
let meshes = try MTKMesh.newMeshes(from: asset, device: device!, sourceMeshes: nil)
{% endhighlight %}

### Step 4: set up `Metal` rendering and drawing of meshes

Finally, we configure the command encoder with the mesh data that it needs to draw:

{% highlight swift %}let mesh = (meshes?.first)!
let vertexBuffer = mesh.vertexBuffers[0]
commandEncoder.setVertexBuffer(vertexBuffer.buffer, offset: vertexBuffer.offset, at: 0)
let submesh = mesh.submeshes.first!
commandEncoder.drawIndexedPrimitives(submesh.primitiveType, indexCount: submesh.indexCount, indexType: submesh.indexType, indexBuffer: submesh.indexBuffer.buffer, indexBufferOffset: submesh.indexBuffer.offset)
{% endhighlight %}

Next, we will work on our shader functions. First we set up our structs for the vertices and uniforms:

{% highlight swift %}struct VertexIn {
    float4 position [[attribute(0)]];
    float4 color [[attribute(1)]];
    float2 texCoords [[attribute(2)]];
    float occlusion [[attribute(3)]];
};

struct VertexOut {
    float4 position [[position]];
    float4 color;
    float2 texCoords;
    float occlusion;
};

struct Uniforms {
    float4x4 modelViewProjectionMatrix;
};
{% endhighlight %}

Notice that we are matching the information we set up in the vertex descriptor, with the `VertexIn` struct.
For the vertex function, we use a __[[stage_in]]__ attribute because we are passing per-vertex inputs as an argument to this function:

{% highlight swift %}vertex VertexOut vertex_func(const VertexIn vertices [[stage_in]],
                             constant Uniforms &amp;uniforms [[buffer(1)]],
                             uint vertexId [[vertex_id]])
{
    float4x4 mvpMatrix = uniforms.modelViewProjectionMatrix;
    float4 position = vertices.position;
    VertexOut out;
    out.position = mvpMatrix * position;
    out.color = float4(1);
    out.texCoords = vertices.texCoords;
    out.occlusion = vertices.occlusion;
    return out;
}
{% endhighlight %}

The fragment function reads the per-fragment inputs passed from the vertex function and also processes the texture we passed via the command encoder: 

{% highlight swift %}fragment half4 fragment_func(VertexOut fragments [[stage_in]],
                             texture2d&lt;float&gt; textures [[texture(0)]])
{
    float4 baseColor = fragments.color;
    return half4(baseColor);
}
{% endhighlight %}

If you run the playground, you will see this output image:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_3.png &quot;3&quot;)

That's a pretty dull white model. Let's apply the ambient occlusion to it by replacing the last line in the fragment function with these lines:

{% highlight swift %}float4 occlusion = fragments.occlusion;
return half4(baseColor * occlusion);
{% endhighlight %}

If you run the playground again, you will see this output image:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_4.png &quot;4&quot;)

The ambient occlusion also seems a bit raw and that is because our model is quite flat, without any curves or surface irregularities which would give way more credit to the realism that the ambient occlusion brings. Next, let's apply the texture. Replace the last line in the fragment function with these lines: 

{% highlight swift %}constexpr sampler samplers;
float4 texture = textures.sample(samplers, fragments.texCoords);
return half4(baseColor * texture);
{% endhighlight %}    

If you run the playground again, you will see this output image:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_5.png &quot;5&quot;)

The texture looks really great on this model, but it would look even more realistic if we brought the ambient occlusion back. Replace the last line in the fragment function with this line: 

{% highlight swift %}return half4(baseColor * occlusion * texture);
{% endhighlight %}

If you run the playground again, you will see this output image:

![alt text](https://github.com/MetalKit/images/raw/master/modelio_6.png &quot;6&quot;)

Not bad for a few lines of code, right? `Model I/O` is such a great framework for `3D` graphics and game programmers. There are a couple of articles on the web about using `Model I/O` with `SceneKit`, however, I thought using it with `Metal` is even more interesting! The [source code](https://github.com/MetalKit/modelio) is posted on Github as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Model I/O was introduced in 2015 for iOS 9 and OS X 10.11 and it is a framework that helps us create more realistic and interactive graphics. We can use it to import/export 3D assets, to describe lighting, materials and environments, to bake lights, to subdivide and voxelize meshes, and for physical based rendering. Model I/O easily integrates our assets with our code in various 3D APIs:



In order to import an asset we simply do:

var url = URL(string: &quot;/Users/YourUsername/Desktop/imported.obj&quot;)
let asset = MDLAsset(url: url!)

To export an asset we do:

url = URL(string: &quot;/Users/YourUsername/Desktop/exported.obj&quot;)
try! asset.export(to: url!)

Model I/O will save both the .obj file and an additional .mtl file that contains information about the object materials, such as in this example:

# Apple ModelI/O MTL File: exported.mtl

newmtl material_1
	Kd 0.8 0.8 0.8
	Ka 0 0 0
	Ks 0 0 0
	ao 0 0 0
	subsurface 0 0 0
	metallic 0 0 0
	specularTint 0 0 0
	roughness 0.9 0 0
	anisotropicRotation 0 0 0
	sheen 0.05 0 0
	sheenTint 0 0 0
	clearCoat 0 0 0
	clearCoatGloss 0 0 0

Integrating Model I/O with Metal takes four steps:



Step 1: set up the render pipeline state

First we create a vertex descriptor so we can pass input to the vertex function. The vertex descriptor is needed to describe the vertex attribute inputs to a render state pipeline. We need 3 x 4 bytes for the vertex position, 4 x 1 byte for color, 2 x 2 bytes for the texture coordinates and 4 x 1 byte for ambient occlusion. At the end we tell the descriptor how large (24) our stride is in total:

let vertexDescriptor = MTLVertexDescriptor()
vertexDescriptor.attributes[0].offset = 0
vertexDescriptor.attributes[0].format = MTLVertexFormat.float3 // position

vertexDescriptor.attributes[1].offset = 12
vertexDescriptor.attributes[1].format = MTLVertexFormat.uChar4 // color

vertexDescriptor.attributes[2].offset = 16
vertexDescriptor.attributes[2].format = MTLVertexFormat.half2 // texture

vertexDescriptor.attributes[3].offset = 20
vertexDescriptor.attributes[3].format = MTLVertexFormat.float // occlusion

vertexDescriptor.layouts[0].stride = 24
let renderPipelineDescriptor = MTLRenderPipelineDescriptor()
renderPipelineDescriptor.vertexDescriptor = vertexDescriptor
let rps = device.newRenderPipelineStateWithDescriptor(renderPipelineDescriptor)

Step 2: set up the asset initialization

We need to also create a Model I/O vertex descriptor to describe the layout of the vertex attributes in a mesh. We use a model named Farmhouse.obj that also has a texture Farmhouse.png (both already added to the sample project for you):

let desc = MTKModelIOVertexDescriptorFromMetal(vertexDescriptor)
var attribute = desc.attributes[0] as! MDLVertexAttribute
attribute.name = MDLVertexAttributePosition
attribute = desc.attributes[1] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeColor
attribute = desc.attributes[2] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeTextureCoordinate
attribute = desc.attributes[3] as! MDLVertexAttribute
attribute.name = MDLVertexAttributeOcclusionValue
let mtkBufferAllocator = MTKMeshBufferAllocator(device: device!)
let url = Bundle.main.url(forResource: &quot;Farmhouse&quot;, withExtension: &quot;obj&quot;)
let asset = MDLAsset(url: url!, vertexDescriptor: desc, bufferAllocator: mtkBufferAllocator)

Next, we load the texture for our asset:

let loader = MTKTextureLoader(device: device)
let file = Bundle.main.path(forResource: &quot;Farmhouse&quot;, ofType: &quot;png&quot;)
let data = try Data(contentsOf: URL(fileURLWithPath: file))
let texture = try loader.newTexture(with: data, options: nil)

Step 3: set up MetalKit mesh and submesh objects

We are now creating the meshes and submeshes needed in the final, fourth step. We also compute the Ambient Occlusion, which is a measure of geometry obstruction, and it tells us how much of the ambient light actually reaches any given pixel or point of our object, and and how much of this light is blocked by surrounding meshes. Model I/O provides a UV mapper that creates a 2D texture and wraps it around the objectâ€™s 3D mesh. For every pixel in the texture we can compute the ambient occlusion value, which is just one extra float added for each vertex:

let mesh = asset.object(at: 0) as? MDLMesh
mesh.generateAmbientOcclusionVertexColors(withQuality: 1, attenuationFactor: 0.98, objectsToConsider: [mesh], vertexAttributeNamed: MDLVertexAttributeOcclusionValue)
let meshes = try MTKMesh.newMeshes(from: asset, device: device!, sourceMeshes: nil)

Step 4: set up Metal rendering and drawing of meshes

Finally, we configure the command encoder with the mesh data that it needs to draw:

let mesh = (meshes?.first)!
let vertexBuffer = mesh.vertexBuffers[0]
commandEncoder.setVertexBuffer(vertexBuffer.buffer, offset: vertexBuffer.offset, at: 0)
let submesh = mesh.submeshes.first!
commandEncoder.drawIndexedPrimitives(submesh.primitiveType, indexCount: submesh.indexCount, indexType: submesh.indexType, indexBuffer: submesh.indexBuffer.buffer, indexBufferOffset: submesh.indexBuffer.offset)

Next, we will work on our shader functions. First we set up our structs for the vertices and uniforms:

struct VertexIn {
    float4 position [[attribute(0)]];
    float4 color [[attribute(1)]];
    float2 texCoords [[attribute(2)]];
    float occlusion [[attribute(3)]];
};

struct VertexOut {
    float4 position [[position]];
    float4 color;
    float2 texCoords;
    float occlusion;
};

struct Uniforms {
    float4x4 modelViewProjectionMatrix;
};

Notice that we are matching the information we set up in the vertex descriptor, with the VertexIn struct.
For the vertex function, we use a [[stage_in]] attribute because we are passing per-vertex inputs as an argument to this function:

vertex VertexOut vertex_func(const VertexIn vertices [[stage_in]],
                             constant Uniforms &amp;amp;uniforms [[buffer(1)]],
                             uint vertexId [[vertex_id]])
{
    float4x4 mvpMatrix = uniforms.modelViewProjectionMatrix;
    float4 position = vertices.position;
    VertexOut out;
    out.position = mvpMatrix * position;
    out.color = float4(1);
    out.texCoords = vertices.texCoords;
    out.occlusion = vertices.occlusion;
    return out;
}

The fragment function reads the per-fragment inputs passed from the vertex function and also processes the texture we passed via the command encoder:

fragment half4 fragment_func(VertexOut fragments [[stage_in]],
                             texture2d&amp;lt;float&amp;gt; textures [[texture(0)]])
{
    float4 baseColor = fragments.color;
    return half4(baseColor);
}

If you run the playground, you will see this output image:



Thatâ€™s a pretty dull white model. Letâ€™s apply the ambient occlusion to it by replacing the last line in the fragment function with these lines:

float4 occlusion = fragments.occlusion;
return half4(baseColor * occlusion);

If you run the playground again, you will see this output image:



The ambient occlusion also seems a bit raw and that is because our model is quite flat, without any curves or surface irregularities which would give way more credit to the realism that the ambient occlusion brings. Next, letâ€™s apply the texture. Replace the last line in the fragment function with these lines:

constexpr sampler samplers;
float4 texture = textures.sample(samplers, fragments.texCoords);
return half4(baseColor * texture);

If you run the playground again, you will see this output image:



The texture looks really great on this model, but it would look even more realistic if we brought the ambient occlusion back. Replace the last line in the fragment function with this line:

return half4(baseColor * occlusion * texture);

If you run the playground again, you will see this output image:



Not bad for a few lines of code, right? Model I/O is such a great framework for 3D graphics and game programmers. There are a couple of articles on the web about using Model I/O with SceneKit, however, I thought using it with Metal is even more interesting! The source code is posted on Github as usual.

Until next time!</summary></entry><entry><title type="html">Ray tracing in a Swift playground part 6</title><link href="http://localhost:4000/2016/08/07/ray-tracing-in-a-swift-playground-part-6.html" rel="alternate" type="text/html" title="Ray tracing in a Swift playground part 6" /><published>2016-08-07T00:00:00-05:00</published><updated>2016-08-07T00:00:00-05:00</updated><id>http://localhost:4000/2016/08/07/ray-tracing-in-a-swift-playground-part-6</id><content type="html" xml:base="http://localhost:4000/2016/08/07/ray-tracing-in-a-swift-playground-part-6.html">Today, I am looking again at the `Ray Tracing` project because I wanted to see how it runs in an `iPad Playground`. There aren't any changes in the core code for now, except I have updated it to run on iOS 10, Xcode 8, Swift 3 and the new iPad Playground app. 

If you run the playground, now you have the option to play with the __number of samples (ns)__ right on the main page of the playground. Fair warning, the higher you set that number, the longer it will take your playground to finish running but the higher the quality of the output image will be. The runtime will also increase if you make the `width` or `height` bigger. For `400 x 200` and `ns = 10`, you will get an image like this:

![alt text](https://github.com/MetalKit/images/raw/master/raytracing_01.png &quot;1&quot;)

In order to get the image to show, you need to tap on the little icon that looks like an image, at the end of the line, and choose `Add viewer`. You could amp up the resolution to say, `800 x 400`, but this will also increase the running time of your playground. However, the output image is worth the waiting!

![alt text](https://github.com/MetalKit/images/raw/master/raytracing_02.png &quot;2&quot;)

We will soon look at ways to make the playground run faster and generate higher quality output images. My good friend and scientific programming guru, [Jeff](https://twitter.com/hyperjeff/), is working on a `Metal`-based version of this raytracer. We will talk about that soon, too. The [source code](https://github.com/MetalKit/raytracing) for the playground in this article is posted on Github as usual.

Until next time!</content><author><name>&lt;a href = &quot;https://twitter.com/MTLDevice&quot; target=&quot;_blank&quot;&gt;Marius Horga&lt;/a&gt;</name></author><summary type="html">Today, I am looking again at the Ray Tracing project because I wanted to see how it runs in an iPad Playground. There arenâ€™t any changes in the core code for now, except I have updated it to run on iOS 10, Xcode 8, Swift 3 and the new iPad Playground app.

If you run the playground, now you have the option to play with the number of samples (ns) right on the main page of the playground. Fair warning, the higher you set that number, the longer it will take your playground to finish running but the higher the quality of the output image will be. The runtime will also increase if you make the width or height bigger. For 400 x 200 and ns = 10, you will get an image like this:



In order to get the image to show, you need to tap on the little icon that looks like an image, at the end of the line, and choose Add viewer. You could amp up the resolution to say, 800 x 400, but this will also increase the running time of your playground. However, the output image is worth the waiting!



We will soon look at ways to make the playground run faster and generate higher quality output images. My good friend and scientific programming guru, Jeff, is working on a Metal-based version of this raytracer. We will talk about that soon, too. The source code for the playground in this article is posted on Github as usual.

Until next time!</summary></entry></feed>
